{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuid3p85tL1YXoWhLxZDCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuu125/Lunette/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "!pip install openai==0.28.1 python-docx notion-client langdetect\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import openai\n",
        "from docx import Document\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client\n",
        "from langdetect import detect, LangDetectException\n",
        "import datetime\n",
        "\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_DB_ID = userdata.get('NOTION_DB_ID')\n",
        "\n",
        "    if not OPENAI_API_KEY:\n",
        "        raise ValueError(\"OPENAI_API_KEY not set\")\n",
        "    if not NOTION_TOKEN:\n",
        "        print(\"‚ö†Ô∏è Notion token missing - feature disabled\")\n",
        "    if not NOTION_DB_ID:\n",
        "        print(\"‚ö†Ô∏è Notion DB ID missing - feature disabled\")\n",
        "\n",
        "    openai.api_key = OPENAI_API_KEY\n",
        "    print(\"‚úÖ OpenAI API key set\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Key retrieval failed: {str(e)}\")\n",
        "\n",
        "def handle_transcript_input():\n",
        "    \"\"\"Handles transcript input methods\"\"\"\n",
        "    print(\"\\n=== Handling Transcript Input ===\")\n",
        "\n",
        "    input_method = input(\"Choose input method (1-upload, 2-paste): \")\n",
        "    transcript_text = \"\"\n",
        "\n",
        "    # File upload handling\n",
        "    if input_method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"‚ö†Ô∏è No files uploaded, switching to paste\")\n",
        "            transcript_text = input(\"Paste meeting transcript: \")\n",
        "        else:\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "            # Text file processing\n",
        "            if filename.endswith('.txt'):\n",
        "                transcript_text = uploaded[filename].decode('utf-8')\n",
        "\n",
        "            # DOCX processing\n",
        "            elif filename.endswith('.docx'):\n",
        "                doc = Document(filename)\n",
        "                transcript_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "    # Text paste handling\n",
        "    elif input_method == \"2\":\n",
        "        transcript_text = input(\"Paste meeting transcript: \")\n",
        "\n",
        "    cleaned_text = clean_transcript(transcript_text)\n",
        "    segments = segment_text(cleaned_text)\n",
        "\n",
        "    print(f\"üìù Processed text: {len(segments)} segments\")\n",
        "    return cleaned_text, segments\n",
        "\n",
        "def test_notion_connection():\n",
        "    \"\"\"Tests Notion API connection\"\"\"\n",
        "    try:\n",
        "        notion = Client(auth=NOTION_TOKEN)\n",
        "        db_info = notion.databases.retrieve(database_id=NOTION_DB_ID)\n",
        "        print(\"‚úÖ Notion connection successful!\")\n",
        "        print(f\"DB Name: {db_info['title'][0]['text']['content']}\")\n",
        "        print(\"DB Properties:\", list(db_info['properties'].keys()))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Notion connection failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def clean_transcript(text):\n",
        "    \"\"\"Cleans raw transcript text\"\"\"\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}:\\d{2}', '', text)\n",
        "    text = re.sub(r'Speaker\\s*\\d+:?', '', text)\n",
        "    return re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
        "\n",
        "def segment_text(text):\n",
        "    \"\"\"Segments text into paragraphs\"\"\"\n",
        "    return [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
        "\n",
        "def analyze_with_gpt(text, language='en'):\n",
        "    \"\"\"Analyzes text with GPT API\"\"\"\n",
        "    print(\"\\n=== Analyzing with GPT ===\")\n",
        "\n",
        "    if not openai.api_key:\n",
        "        print(\"‚ùå OpenAI API key missing\")\n",
        "        return {\"error\": \"OpenAI API key not set\", \"fallback_used\": True}, 0\n",
        "\n",
        "    # Language mapping\n",
        "    lang_map = {'zh': 'Chinese', 'es': 'Spanish', 'fr': 'French', 'en': 'English'}\n",
        "    lang_name = lang_map.get(language[:2], 'English')\n",
        "\n",
        "    # System prompt setup\n",
        "    system_prompt = f\"\"\"\n",
        "    You are a professional meeting analyst. Extract key information:\n",
        "    - Respond in {lang_name}\n",
        "    - Use this JSON format:\n",
        "    {{\n",
        "        \"meeting_title\": \"Meeting Title\",\n",
        "        \"participants\": [\"Attendee1\", \"Attendee2\"],\n",
        "        \"summary\": \"Meeting summary\",\n",
        "        \"action_items\": [{{\"task\": \"Task\", \"assignee\": \"Owner\"}}],\n",
        "        \"key_points\": {{\n",
        "            \"concerns\": [],\n",
        "            \"decisions\": [],\n",
        "            \"deadlines\": [],\n",
        "            \"updates\": []\n",
        "        }},\n",
        "        \"meeting_type\": \"Meeting type\",\n",
        "        \"platform\": \"Platform\",\n",
        "        \"fallback_used\": false\n",
        "    }}\n",
        "\n",
        "    Extraction rules:\n",
        "    1. meeting_title: Extract from start/end or generate\n",
        "    2. participants: Extract all attendees\n",
        "    3. Focus on meeting start/end sections\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"Meeting transcript:\\n{text[:10000]}\"\n",
        "\n",
        "    try:\n",
        "        # GPT API call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message['content']\n",
        "        result = json.loads(content)\n",
        "        tokens_used = response.usage['total_tokens']\n",
        "\n",
        "        print(f\"‚úÖ GPT analysis complete! Tokens: {tokens_used}\")\n",
        "        print(f\"Meeting title: {result.get('meeting_title', 'N/A')}\")\n",
        "        print(f\"Participants: {len(result.get('participants', []))}\")\n",
        "        print(f\"Meeting type: {result.get('meeting_type', 'N/A')}\")\n",
        "        print(f\"Action items: {len(result.get('action_items', []))}\")\n",
        "\n",
        "        # Fallback for action items\n",
        "        if not result.get('action_items'):\n",
        "            result['fallback_used'] = True\n",
        "            print(\"‚ö†Ô∏è No action items detected\")\n",
        "\n",
        "        return result, tokens_used\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå GPT analysis failed: {str(e)}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"fallback_used\": True\n",
        "        }, 0\n",
        "\n",
        "def create_notion_entry(meeting_data):\n",
        "    \"\"\"Creates Notion database entry\"\"\"\n",
        "    if not NOTION_TOKEN or not NOTION_DB_ID:\n",
        "        print(\"‚ö†Ô∏è Notion config incomplete - skipping\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\n=== Syncing to Notion ===\")\n",
        "\n",
        "    try:\n",
        "        notion = Client(auth=NOTION_TOKEN)\n",
        "\n",
        "        # Prepare properties\n",
        "        properties = {\n",
        "            \"Meeting Title\": {\"title\": [{\"text\": {\"content\": meeting_data.get(\"meeting_title\", \"Untitled\")}}]},\n",
        "            \"Participant\": {\"rich_text\": [{\"text\": {\"content\": \", \".join(meeting_data.get(\"participants\", [\"Unknown\"]))}}]},\n",
        "            \"Date & Duration\": {\"date\": {\"start\": meeting_data.get(\"date\", datetime.datetime.now().isoformat())}},\n",
        "            \"Meeting Type\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get(\"meeting_type\", \"Other\")}}]},\n",
        "            \"Platform\": {\"select\": {\"name\": meeting_data.get(\"platform\", \"Unknown\")}},\n",
        "            \"Summary\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get(\"summary\", \"\")}}]},\n",
        "            \"Key Points\": {\"rich_text\": [{\"text\": {\"content\": format_key_points(meeting_data)}}]},\n",
        "            \"Action Items\": {\"rich_text\": [{\"text\": {\"content\": format_action_items(meeting_data)}}]},\n",
        "        }\n",
        "\n",
        "        # Create entry\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"database_id\": NOTION_DB_ID},\n",
        "            properties=properties\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Notion entry created! ID: {new_page['id']}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Notion sync failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def format_key_points(data):\n",
        "    \"\"\"Formats key points for Notion\"\"\"\n",
        "    points = []\n",
        "    key_points = data.get(\"key_points\", {})\n",
        "    for category, items in key_points.items():\n",
        "        if items and isinstance(items, list):\n",
        "            points.append(f\"{category.upper()}:\")\n",
        "            points.extend([f\"- {item}\" for item in items])\n",
        "    return \"\\n\".join(points)\n",
        "\n",
        "def format_action_items(data):\n",
        "    \"\"\"Formats action items for Notion\"\"\"\n",
        "    action_items = data.get(\"action_items\", [])\n",
        "    if not action_items or not isinstance(action_items, list):\n",
        "        return \"No action items\"\n",
        "\n",
        "    formatted = []\n",
        "    for item in action_items:\n",
        "        if isinstance(item, dict):\n",
        "            task = item.get('task', 'Unknown task')\n",
        "            assignee = item.get('assignee', 'Unassigned')\n",
        "            formatted.append(f\"- {task} (Owner: {assignee})\")\n",
        "        else:\n",
        "            formatted.append(f\"- {str(item)}\")\n",
        "    return \"\\n\".join(formatted)\n",
        "\n",
        "def setup_whisper():\n",
        "    \"\"\"Installs Whisper dependencies\"\"\"\n",
        "    print(\"\\n=== Setting up Whisper ===\")\n",
        "    !pip install git+https://github.com/openai/whisper.git\n",
        "    !sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "    uploaded_audio = files.upload()\n",
        "    if uploaded_audio:\n",
        "        audio_file = list(uploaded_audio.keys())[0]\n",
        "        print(f\"üîä Audio sample: {audio_file}\")\n",
        "        return audio_file\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main workflow execution\"\"\"\n",
        "    if not openai.api_key:\n",
        "        print(\"‚ùå OpenAI API key missing\")\n",
        "        return\n",
        "\n",
        "    logs = {\"steps\": [], \"errors\": []}\n",
        "\n",
        "    # Test Notion connection\n",
        "    if NOTION_TOKEN and NOTION_DB_ID:\n",
        "        if not test_notion_connection():\n",
        "            print(\"‚ö†Ô∏è Notion connection failed\")\n",
        "\n",
        "    try:\n",
        "        # Process input\n",
        "        cleaned_text, segments = handle_transcript_input()\n",
        "        logs[\"steps\"].append({\n",
        "            \"step\": \"Text input\",\n",
        "            \"segment_count\": len(segments),\n",
        "            \"status\": \"success\"\n",
        "        })\n",
        "\n",
        "        # Detect language\n",
        "        try:\n",
        "            language = detect(cleaned_text[:500]) if cleaned_text else 'en'\n",
        "        except LangDetectException:\n",
        "            language = 'en'\n",
        "\n",
        "        # GPT analysis\n",
        "        gpt_results, tokens_used = analyze_with_gpt(cleaned_text, language)\n",
        "\n",
        "        if \"error\" in gpt_results:\n",
        "            logs[\"steps\"].append({\n",
        "                \"step\": \"GPT analysis\",\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": gpt_results[\"error\"]\n",
        "            })\n",
        "            print(f\"‚ùå GPT failed: {gpt_results['error']}\")\n",
        "            return\n",
        "        else:\n",
        "            logs[\"steps\"].append({\n",
        "                \"step\": \"GPT analysis\",\n",
        "                \"tokens_used\": tokens_used,\n",
        "                \"meeting_title\": gpt_results.get(\"meeting_title\"),\n",
        "                \"participants_count\": len(gpt_results.get(\"participants\", [])),\n",
        "                \"meeting_type\": gpt_results.get(\"meeting_type\"),\n",
        "                \"action_items_count\": len(gpt_results.get(\"action_items\", [])),\n",
        "                \"status\": \"success\"\n",
        "            })\n",
        "\n",
        "        # Add date and sync to Notion\n",
        "        gpt_results[\"date\"] = datetime.datetime.now().isoformat()\n",
        "        notion_success = create_notion_entry(gpt_results)\n",
        "        logs[\"steps\"].append({\n",
        "            \"step\": \"Notion sync\",\n",
        "            \"status\": \"success\" if notion_success else \"failed\"\n",
        "        })\n",
        "\n",
        "        # Save logs\n",
        "        with open(\"meeting_logs.json\", \"w\") as f:\n",
        "            json.dump(logs, f, indent=2)\n",
        "\n",
        "        print(\"\\n‚úÖ Process complete! Logs saved\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logs[\"errors\"].append(str(e))\n",
        "        print(f\"\\n‚ùå Process error: {str(e)}\")\n",
        "        with open(\"error_log.json\", \"w\") as f:\n",
        "            json.dump(logs, f, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "qq1cOplyCeys",
        "outputId": "4e18e87a-d4aa-41aa-d8f8-85a7633459f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: notion-client in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (3.11.15)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from notion-client) (0.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion-client) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->notion-client) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.20.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->notion-client) (1.3.1)\n",
            "‚úÖ OpenAI API key set\n",
            "‚úÖ Notion connection successful!\n",
            "DB Name: üìÑ Meeting Logs\n",
            "DB Properties: ['Date & Duration', 'Key Points', 'Platform', 'Participant', 'Summary', 'Action Items', 'Meeting Type', 'Meeting Title']\n",
            "\n",
            "=== Handling Transcript Input ===\n",
            "Choose input method (1-upload, 2-paste): 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d96e05cc-7816-4dbf-8c73-1c8edb0dd933\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d96e05cc-7816-4dbf-8c73-1c8edb0dd933\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ‰ºöËÆÆËÆ∞ÂΩï.docx to ‰ºöËÆÆËÆ∞ÂΩï (7).docx\n",
            "‚úÖ Uploaded: ‰ºöËÆÆËÆ∞ÂΩï (7).docx\n",
            "üìù Processed text: 1 segments\n",
            "\n",
            "=== Analyzing with GPT ===\n",
            "‚úÖ GPT analysis complete! Tokens: 1432\n",
            "Meeting title: È°πÁõÆËøõÂ∫¶Ê±áÊä•‰∏éËÆ®ËÆ∫\n",
            "Participants: 6\n",
            "Meeting type: È°πÁõÆËøõÂ∫¶Ê±áÊä•‰∏éËÆ®ËÆ∫\n",
            "Action items: 3\n",
            "\n",
            "=== Syncing to Notion ===\n",
            "‚úÖ Notion entry created! ID: 2305fee1-8e37-81a0-a874-f76428a7e501\n",
            "\n",
            "‚úÖ Process complete! Logs saved\n"
          ]
        }
      ]
    }
  ]
}