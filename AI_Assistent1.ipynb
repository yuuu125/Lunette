{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuu125/Lunette/blob/main/AI_Assistent1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qq1cOplyCeys",
        "outputId": "0fbf4c40-78da-4f57-f41f-8de9f4108d3b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: notion-client in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (3.11.15)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: httpx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from notion-client) (0.27.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15.0->notion-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15.0->notion-client) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15.0->notion-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15.0->notion-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15.0->notion-client) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.15.0->notion-client) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.20.1)\n",
            "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.37.0\n",
            "    Uninstalling openai-1.37.0:\n",
            "      Successfully uninstalled openai-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.1.9 requires openai<2.0.0,>=1.26.0, but you have openai 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "b634d9af59154da7badf30a5a3d8b596"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-c6cshuv1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-c6cshuv1\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28.1 python-docx notion-client langdetect pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg  # 确保安装必要的依赖\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import openai\n",
        "import whisper\n",
        "from docx import Document\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client\n",
        "from langdetect import detect, LangDetectException\n",
        "import datetime\n",
        "import tempfile\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_DB_ID = userdata.get('NOTION_DB_ID')\n",
        "\n",
        "    if not OPENAI_API_KEY:\n",
        "        raise ValueError(\"OPENAI_API_KEY not set\")\n",
        "    if not NOTION_TOKEN:\n",
        "        print(\"⚠️ Notion token missing - feature disabled\")\n",
        "    if not NOTION_DB_ID:\n",
        "        print(\"⚠️ Notion DB ID missing - feature disabled\")\n",
        "\n",
        "    openai.api_key = OPENAI_API_KEY\n",
        "    print(\"✅ OpenAI API key set\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Key retrieval failed: {str(e)}\")\n",
        "\n",
        "def get_audio_duration(audio_path):\n",
        "    \"\"\"使用ffmpeg获取精确音频时长（秒）\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "             \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        return float(result.stdout)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 无法获取精确时长，使用估算值: {e}\")\n",
        "        # 估算：8KB/s 是常见音频比特率\n",
        "        return max(30, os.path.getsize(audio_path) // 8000)\n",
        "\n",
        "def transcribe_audio(audio_path, model_size=\"base\"):\n",
        "    \"\"\"使用Whisper转录音频文件\"\"\"\n",
        "    print(f\"🔊 Starting transcription with Whisper ({model_size} model)...\")\n",
        "\n",
        "    try:\n",
        "        # 检查GPU加速\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"💻 Using device: {device.upper()}\")\n",
        "\n",
        "        # 加载模型\n",
        "        model = whisper.load_model(model_size, device=device)\n",
        "        print(f\"✅ Loaded Whisper {model_size} model\")\n",
        "\n",
        "        # 转录音频\n",
        "        result = model.transcribe(\n",
        "            audio_path,\n",
        "            fp16=(device == \"cuda\"),\n",
        "            verbose=True,\n",
        "            task=\"transcribe\"\n",
        "        )\n",
        "\n",
        "        transcription = result[\"text\"]\n",
        "        print(f\"✅ Transcription complete! Characters: {len(transcription)}\")\n",
        "        return transcription\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Transcription failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def test_notion_connection():\n",
        "    \"\"\"测试Notion连接是否有效\"\"\"\n",
        "    try:\n",
        "        # 初始化Notion客户端，显式配置客户端禁用代理\n",
        "        notion = Client(\n",
        "        auth=NOTION_TOKEN,\n",
        "        client=httpx.Client(proxies=None)  # 显式禁用代理\n",
        "        )\n",
        "        notion.databases.retrieve(database_id=NOTION_DB_ID)\n",
        "        print(\"✅ Notion connection verified\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Notion connection failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def clean_transcript(text):\n",
        "    \"\"\"Cleans raw transcript text\"\"\"\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}:\\d{2}', '', text)\n",
        "    text = re.sub(r'Speaker\\s*\\d+:?', '', text)\n",
        "    return re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
        "\n",
        "def segment_text(text):\n",
        "    \"\"\"Segments text into paragraphs\"\"\"\n",
        "    return [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
        "\n",
        "def handle_transcript_input():\n",
        "    \"\"\"Handles transcript input methods\"\"\"\n",
        "    print(\"\\n=== Handling Transcript Input ===\")\n",
        "    print(\"Choose input method:\")\n",
        "    print(\"1 - Upload text file (.txt or .docx)\")\n",
        "    print(\"2 - Paste text directly\")\n",
        "    print(\"3 - Upload audio file (transcribe with Whisper)\")\n",
        "\n",
        "    input_method = input(\"Your choice (1/2/3): \")\n",
        "    transcript_text = \"\"\n",
        "\n",
        "    # 文本文件上传\n",
        "    if input_method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"⚠️ No files uploaded, switching to paste\")\n",
        "            transcript_text = input(\"Paste meeting transcript: \")\n",
        "        else:\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            print(f\"✅ Uploaded: {filename}\")\n",
        "\n",
        "            # 文本文件处理\n",
        "            if filename.endswith('.txt'):\n",
        "                transcript_text = uploaded[filename].decode('utf-8')\n",
        "\n",
        "            # DOCX处理\n",
        "            elif filename.endswith('.docx'):\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:\n",
        "                    tmp.write(uploaded[filename])\n",
        "                    tmp_path = tmp.name\n",
        "\n",
        "                doc = Document(tmp_path)\n",
        "                transcript_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "                os.unlink(tmp_path)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "    # 文本粘贴\n",
        "    elif input_method == \"2\":\n",
        "        transcript_text = input(\"Paste meeting transcript: \")\n",
        "\n",
        "    # 音频文件处理\n",
        "    elif input_method == \"3\":\n",
        "        uploaded_audio = files.upload()\n",
        "        if not uploaded_audio:\n",
        "            print(\"⚠️ No audio files uploaded, switching to text paste\")\n",
        "            transcript_text = input(\"Paste meeting transcript: \")\n",
        "        else:\n",
        "            filename = list(uploaded_audio.keys())[0]\n",
        "            print(f\"✅ Uploaded audio: {filename}\")\n",
        "\n",
        "            # 创建临时文件\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(filename)[1]) as tmp:\n",
        "                tmp.write(uploaded_audio[filename])\n",
        "                audio_path = tmp.name\n",
        "\n",
        "            print(\"\\n⚡ Select transcription speed:\")\n",
        "            print(\"1 - Fast (tiny model, fastest, lower accuracy)\")\n",
        "            print(\"2 - Balanced (base model, recommended)\")\n",
        "            print(\"3 - High Quality (small model, slower)\")\n",
        "\n",
        "            speed_choice = input(\"Your choice (1/2/3): \") or \"2\"\n",
        "            model_map = {\"1\": \"tiny\", \"2\": \"base\", \"3\": \"small\"}\n",
        "            model_size = model_map.get(speed_choice, \"base\")\n",
        "\n",
        "            # 获取音频时长\n",
        "            try:\n",
        "                duration = get_audio_duration(audio_path)\n",
        "                print(f\"⏱ Audio duration: {duration//60:.0f}m {duration%60:.0f}s\")\n",
        "\n",
        "                # 时间估算\n",
        "                time_estimates = {\"tiny\": 0.3, \"base\": 0.8, \"small\": 2.0}\n",
        "                est_sec = duration * time_estimates[model_size]\n",
        "                print(f\"⏳ Estimated processing time: ~{est_sec//60:.0f}m {est_sec%60:.0f}s\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Duration estimation failed: {e}\")\n",
        "\n",
        "            # 转录音频\n",
        "            transcript_text = transcribe_audio(audio_path, model_size)\n",
        "\n",
        "            # 清理临时文件\n",
        "            os.unlink(audio_path)\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ Invalid option, defaulting to text paste\")\n",
        "        transcript_text = input(\"Paste meeting transcript: \")\n",
        "\n",
        "    cleaned_text = clean_transcript(transcript_text)\n",
        "    segments = segment_text(cleaned_text)\n",
        "\n",
        "    print(f\"📝 Processed text: {len(segments)} segments, {len(cleaned_text)} characters\")\n",
        "    return cleaned_text, segments\n",
        "\n",
        "def analyze_with_gpt(text, language='en'):\n",
        "    \"\"\"Analyzes text with GPT API\"\"\"\n",
        "    print(\"\\n=== Analyzing with GPT ===\")\n",
        "\n",
        "    if not openai.api_key:\n",
        "        print(\"❌ OpenAI API key missing\")\n",
        "        return {\"error\": \"OpenAI API key not set\", \"fallback_used\": True}, 0\n",
        "\n",
        "    # Language mapping\n",
        "    lang_map = {'zh': 'Chinese', 'es': 'Spanish', 'fr': 'French', 'en': 'English'}\n",
        "    lang_name = lang_map.get(language[:2], 'English')\n",
        "\n",
        "    # System prompt setup\n",
        "    system_prompt = f\"\"\"\n",
        "    You are a professional meeting analyst. Extract key information:\n",
        "    - Respond in {lang_name}\n",
        "    - Use this JSON format:\n",
        "    {{\n",
        "        \"meeting_title\": \"Meeting Title\",\n",
        "        \"participants\": [\"Attendee1\", \"Attendee2\"],\n",
        "        \"summary\": \"Meeting summary\",\n",
        "        \"action_items\": [{{\"task\": \"Task\", \"assignee\": \"Owner\"}}],\n",
        "        \"key_points\": {{\n",
        "            \"concerns\": [],\n",
        "            \"decisions\": [],\n",
        "            \"deadlines\": [],\n",
        "            \"updates\": []\n",
        "        }},\n",
        "        \"meeting_type\": \"Meeting type\",\n",
        "        \"platform\": \"Platform\",\n",
        "        \"fallback_used\": false\n",
        "    }}\n",
        "\n",
        "    Extraction rules:\n",
        "    1. meeting_title: Extract from start/end or generate\n",
        "    2. participants: Extract all attendees\n",
        "    3. Focus on meeting start/end sections\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"Meeting transcript:\\n{text[:10000]}\"\n",
        "\n",
        "    try:\n",
        "        # GPT API call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message['content']\n",
        "        result = json.loads(content)\n",
        "        tokens_used = response.usage['total_tokens']\n",
        "\n",
        "        print(f\"✅ GPT analysis complete! Tokens: {tokens_used}\")\n",
        "        print(f\"Meeting title: {result.get('meeting_title', 'N/A')}\")\n",
        "        print(f\"Participants: {len(result.get('participants', []))}\")\n",
        "        print(f\"Meeting type: {result.get('meeting_type', 'N/A')}\")\n",
        "        print(f\"Action items: {len(result.get('action_items', []))}\")\n",
        "\n",
        "        # Fallback for action items\n",
        "        if not result.get('action_items'):\n",
        "            result['fallback_used'] = True\n",
        "            print(\"⚠️ No action items detected\")\n",
        "\n",
        "        return result, tokens_used\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ GPT analysis failed: {str(e)}\")\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"fallback_used\": True\n",
        "        }, 0\n",
        "\n",
        "def create_notion_entry(meeting_data):\n",
        "    \"\"\"Creates Notion database entry\"\"\"\n",
        "    if not NOTION_TOKEN or not NOTION_DB_ID:\n",
        "        print(\"⚠️ Notion config incomplete - skipping\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\n=== Syncing to Notion ===\")\n",
        "\n",
        "    try:\n",
        "        # 初始化Notion客户端，显式配置客户端禁用代理\n",
        "        notion = Client(\n",
        "        auth=NOTION_TOKEN,\n",
        "        client=httpx.Client(proxies=None)  # 显式禁用代理\n",
        ")\n",
        "\n",
        "        # Prepare properties\n",
        "        properties = {\n",
        "            \"Meeting Title\": {\"title\": [{\"text\": {\"content\": meeting_data.get(\"meeting_title\", \"Untitled\")}}]},\n",
        "            \"Participant\": {\"rich_text\": [{\"text\": {\"content\": \", \".join(meeting_data.get(\"participants\", [\"Unknown\"]))}}]},\n",
        "            \"Date & Duration\": {\"date\": {\"start\": meeting_data.get(\"date\", datetime.datetime.now().isoformat())}},\n",
        "            \"Meeting Type\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get(\"meeting_type\", \"Other\")}}]},\n",
        "            \"Platform\": {\"select\": {\"name\": meeting_data.get(\"platform\", \"Unknown\")}},\n",
        "            \"Summary\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get(\"summary\", \"\")}}]},\n",
        "            \"Key Points\": {\"rich_text\": [{\"text\": {\"content\": format_key_points(meeting_data)}}]},\n",
        "            \"Action Items\": {\"rich_text\": [{\"text\": {\"content\": format_action_items(meeting_data)}}]},\n",
        "        }\n",
        "\n",
        "        # Create entry\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"database_id\": NOTION_DB_ID},\n",
        "            properties=properties\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Notion entry created! ID: {new_page['id']}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Notion sync failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def format_key_points(data):\n",
        "    \"\"\"Formats key points for Notion\"\"\"\n",
        "    points = []\n",
        "    key_points = data.get(\"key_points\", {})\n",
        "    for category, items in key_points.items():\n",
        "        if items and isinstance(items, list):\n",
        "            points.append(f\"{category.upper()}:\")\n",
        "            points.extend([f\"- {item}\" for item in items])\n",
        "    return \"\\n\".join(points)\n",
        "\n",
        "def format_action_items(data):\n",
        "    \"\"\"Formats action items for Notion\"\"\"\n",
        "    action_items = data.get(\"action_items\", [])\n",
        "    if not action_items or not isinstance(action_items, list):\n",
        "        return \"No action items\"\n",
        "\n",
        "    formatted = []\n",
        "    for item in action_items:\n",
        "        if isinstance(item, dict):\n",
        "            task = item.get('task', 'Unknown task')\n",
        "            assignee = item.get('assignee', 'Unassigned')\n",
        "            formatted.append(f\"- {task} (Owner: {assignee})\")\n",
        "        else:\n",
        "            formatted.append(f\"- {str(item)}\")\n",
        "    return \"\\n\".join(formatted)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main workflow execution\"\"\"\n",
        "    if not openai.api_key:\n",
        "        print(\"❌ OpenAI API key missing\")\n",
        "        return\n",
        "\n",
        "    logs = {\"steps\": [], \"errors\": []}\n",
        "\n",
        "    # Test Notion connection\n",
        "    if NOTION_TOKEN and NOTION_DB_ID:\n",
        "        if not test_notion_connection():\n",
        "            print(\"⚠️ Notion connection failed\")\n",
        "\n",
        "    try:\n",
        "        # Process input\n",
        "        cleaned_text, segments = handle_transcript_input()\n",
        "        logs[\"steps\"].append({\n",
        "            \"step\": \"Text input\",\n",
        "            \"segment_count\": len(segments),\n",
        "            \"status\": \"success\"\n",
        "        })\n",
        "\n",
        "        # Detect language\n",
        "        try:\n",
        "            language = detect(cleaned_text[:500]) if cleaned_text else 'en'\n",
        "        except LangDetectException:\n",
        "            language = 'en'\n",
        "        print(f\"🌐 Detected language: {language}\")\n",
        "\n",
        "        # GPT analysis\n",
        "        gpt_results, tokens_used = analyze_with_gpt(cleaned_text, language)\n",
        "\n",
        "        if \"error\" in gpt_results:\n",
        "            logs[\"steps\"].append({\n",
        "                \"step\": \"GPT analysis\",\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": gpt_results[\"error\"]\n",
        "            })\n",
        "            print(f\"❌ GPT failed: {gpt_results['error']}\")\n",
        "            return\n",
        "        else:\n",
        "            logs[\"steps\"].append({\n",
        "                \"step\": \"GPT analysis\",\n",
        "                \"tokens_used\": tokens_used,\n",
        "                \"meeting_title\": gpt_results.get(\"meeting_title\"),\n",
        "                \"participants_count\": len(gpt_results.get(\"participants\", [])),\n",
        "                \"meeting_type\": gpt_results.get(\"meeting_type\"),\n",
        "                \"action_items_count\": len(gpt_results.get(\"action_items\", [])),\n",
        "                \"status\": \"success\"\n",
        "            })\n",
        "\n",
        "        # Add date and sync to Notion\n",
        "        gpt_results[\"date\"] = datetime.datetime.now().isoformat()\n",
        "        notion_success = create_notion_entry(gpt_results)\n",
        "        logs[\"steps\"].append({\n",
        "            \"step\": \"Notion sync\",\n",
        "            \"status\": \"success\" if notion_success else \"failed\"\n",
        "        })\n",
        "\n",
        "        # Save logs\n",
        "        with open(\"meeting_logs.json\", \"w\") as f:\n",
        "            json.dump(logs, f, indent=2)\n",
        "\n",
        "        print(\"\\n✅ Process complete! Logs saved\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logs[\"errors\"].append(str(e))\n",
        "        print(f\"\\n❌ Process error: {str(e)}\")\n",
        "        with open(\"error_log.json\", \"w\") as f:\n",
        "            json.dump(logs, f, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsNbU1oC8N9I",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 安装依赖\n",
        "!pip uninstall -y langchain langchain-core langchain-community langchain-openai openai notion-client\n",
        "!pip install langchain==0.2.0\n",
        "!pip install langchain-core==0.2.38\n",
        "!pip install langchain-community==0.2.0\n",
        "!pip install langchain-openai==0.1.9\n",
        "!pip install openai==1.37.0\n",
        "!pip install notion-client==2.0.0\n",
        "!pip install tqdm python-docx langdetect pydub httpx==0.27.0\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import openai\n",
        "import whisper\n",
        "from docx import Document\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client, errors\n",
        "from langdetect import detect, LangDetectException\n",
        "import datetime\n",
        "import tempfile\n",
        "import torch\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "import httpx\n",
        "\n",
        "# 清除代理环境变量\n",
        "for var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:\n",
        "    if var in os.environ:\n",
        "        del os.environ[var]\n",
        "\n",
        "# 初始化Notion客户端\n",
        "notion = Client(\n",
        "    auth=userdata.get('NOTION_TOKEN'),\n",
        "    client=httpx.Client(proxies=None)\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 初始化设置\n",
        "# ======================\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_DB_ID = userdata.get('NOTION_DB_ID')\n",
        "    NOTION_PAGE_ID = userdata.get('NOTION_PAGE_ID')\n",
        "\n",
        "    missing_creds = []\n",
        "    if not OPENAI_API_KEY:\n",
        "        missing_creds.append(\"OPENAI_API_KEY\")\n",
        "    if not NOTION_TOKEN:\n",
        "        missing_creds.append(\"NOTION_TOKEN\")\n",
        "    if not NOTION_DB_ID:\n",
        "        missing_creds.append(\"NOTION_DB_ID\")\n",
        "    if not NOTION_PAGE_ID:\n",
        "        missing_creds.append(\"NOTION_PAGE_ID\")\n",
        "\n",
        "    if missing_creds:\n",
        "        raise ValueError(f\"缺少凭证: {', '.join(missing_creds)}\")\n",
        "\n",
        "    print(\"✅ 所有凭证已设置\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 凭证获取失败: {str(e)}\")\n",
        "    print(\"\\n🔧 设置说明:\")\n",
        "    print(\"1. 点击左侧边栏的钥匙图标（Colab密钥）\")\n",
        "    print(\"2. 添加以下密钥:\")\n",
        "    print(\"   - OPENAI_API_KEY: 你的OpenAI API密钥\")\n",
        "    print(\"   - NOTION_TOKEN: 你的Notion集成令牌\")\n",
        "    print(\"   - NOTION_DB_ID: Notion数据库ID\")\n",
        "    print(\"   - NOTION_PAGE_ID: 报告父页面ID\")\n",
        "    print(\"3. 添加后重新运行此单元格\")\n",
        "    raise\n",
        "\n",
        "# ======================\n",
        "# 日志系统\n",
        "# ======================\n",
        "class MeetingLogger:\n",
        "    def __init__(self):\n",
        "        self.logs = {\n",
        "            \"start_time\": datetime.datetime.now().isoformat(),\n",
        "            \"steps\": [],\n",
        "            \"errors\": [],\n",
        "            \"metrics\": {}\n",
        "        }\n",
        "\n",
        "    def log_step(self, step_name, status, details=None, error=None):\n",
        "        entry = {\n",
        "            \"step\": step_name,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"status\": status\n",
        "        }\n",
        "        if details:\n",
        "            entry[\"details\"] = details\n",
        "        if error:\n",
        "            entry[\"error\"] = str(error)\n",
        "        self.logs[\"steps\"].append(entry)\n",
        "\n",
        "    def log_metric(self, name, value):\n",
        "        self.logs[\"metrics\"][name] = value\n",
        "\n",
        "    def save_logs(self, filename=\"meeting_logs.json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(self.logs, f, indent=2)\n",
        "        return filename\n",
        "\n",
        "    def get_console_log(self):\n",
        "        log_str = f\"=== 会议处理日志 ===\\n\"\n",
        "        log_str += f\"开始时间: {self.logs['start_time']}\\n\"\n",
        "\n",
        "        for step in self.logs[\"steps\"]:\n",
        "            status_icon = \"✅\" if step[\"status\"] == \"success\" else \"❌\"\n",
        "            log_str += f\"{status_icon} [{step['timestamp']}] {step['step']}\"\n",
        "            if \"details\" in step:\n",
        "                log_str += f\" - {step['details']}\"\n",
        "            if step[\"status\"] == \"failed\":\n",
        "                log_str += f\" - 错误: {step.get('error', '未知')}\"\n",
        "            log_str += \"\\n\"\n",
        "\n",
        "        if self.logs[\"metrics\"]:\n",
        "            log_str += \"\\n=== 指标 ===\\n\"\n",
        "            for metric, value in self.logs[\"metrics\"].items():\n",
        "                log_str += f\"- {metric}: {value}\\n\"\n",
        "\n",
        "        return log_str\n",
        "\n",
        "logger = MeetingLogger()\n",
        "\n",
        "# ======================\n",
        "# 工具函数：处理嵌套结构\n",
        "# ======================\n",
        "def flatten_key_points(key_points):\n",
        "    \"\"\"将key_points中的嵌套结构（字典/列表）转换为字符串，适配Notion格式\"\"\"\n",
        "    flattened = {}\n",
        "    for category, items in key_points.items():\n",
        "        flattened_items = []\n",
        "        for item in items:\n",
        "            # 处理字典类型（如{\"部门\": [\"问题1\", \"问题2\"]}）\n",
        "            if isinstance(item, dict):\n",
        "                dict_strings = []\n",
        "                for k, v in item.items():\n",
        "                    # 字典的值如果是列表，转换为带符号的字符串\n",
        "                    if isinstance(v, list):\n",
        "                        list_str = \"• \".join([str(i) for i in v])\n",
        "                        dict_strings.append(f\"{k}：• {list_str}\")\n",
        "                    else:\n",
        "                        dict_strings.append(f\"{k}：{v}\")\n",
        "                flattened_items.append(\"； \".join(dict_strings))\n",
        "\n",
        "            # 处理列表类型（如[\"问题1\", \"问题2\"]）\n",
        "            elif isinstance(item, list):\n",
        "                list_str = \"• \".join([str(i) for i in item])\n",
        "                flattened_items.append(f\"• {list_str}\")\n",
        "\n",
        "            # 字符串直接保留\n",
        "            else:\n",
        "                flattened_items.append(str(item))\n",
        "        flattened[category] = flattened_items\n",
        "    return flattened\n",
        "\n",
        "# ======================\n",
        "# 音频处理\n",
        "# ======================\n",
        "def get_audio_duration(audio_path):\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "             \"-of\", \"default=noprint_wrappers=1:nokey=1\", audio_path],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        duration = float(result.stdout)\n",
        "        logger.log_metric(\"音频时长(秒)\", duration)\n",
        "        return duration\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"获取音频时长\", \"warning\", error=e)\n",
        "        return max(30, os.path.getsize(audio_path) // 8000)\n",
        "\n",
        "def transcribe_audio(audio_path, model_size=\"base\"):\n",
        "    logger.log_step(\"音频转录\", \"started\", {\"模型大小\": model_size, \"音频路径\": audio_path})\n",
        "\n",
        "    try:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        logger.log_step(\"硬件检查\", \"success\", {\"设备\": device})\n",
        "\n",
        "        model = whisper.load_model(model_size, device=device)\n",
        "        logger.log_step(\"加载模型\", \"success\")\n",
        "\n",
        "        result = model.transcribe(\n",
        "            audio_path,\n",
        "            fp16=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "            task=\"transcribe\"\n",
        "        )\n",
        "\n",
        "        transcription = result[\"text\"]\n",
        "        detected_lang = result[\"language\"]\n",
        "        logger.log_step(\"音频转录\", \"success\", {\n",
        "            \"字符数\": len(transcription),\n",
        "            \"检测语言\": detected_lang\n",
        "        })\n",
        "\n",
        "        return transcription, detected_lang\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频转录\", \"failed\", error=e)\n",
        "        raise\n",
        "\n",
        "# ======================\n",
        "# 会议分析模型与处理\n",
        "# ======================\n",
        "class MeetingAnalysis(BaseModel):\n",
        "    meeting_title: str = Field(description=\"会议标题\")\n",
        "    participants: list[str] = Field(description=\"参与者名单\")\n",
        "    summary: str = Field(description=\"3-5段会议总结\")\n",
        "    key_points: dict = Field(description=\"按concerns、decisions、updates、risks分组的关键点（均为数组）\")\n",
        "    action_items: list[dict] = Field(description=\"行动项列表，包含task、assignee、due_date\")\n",
        "    meeting_type: str = Field(description=\"会议类型\")\n",
        "    platform: str = Field(description=\"会议平台\")\n",
        "\n",
        "def setup_langchain_chains(language='zh'):\n",
        "    lang_map = {\n",
        "        'zh': \"用中文分析会议记录，输出严格符合JSON格式，key_points的子字段均为数组（用[]包裹）\",\n",
        "        'en': \"Analyze the meeting transcript in English, output strict JSON with key_points as arrays\",\n",
        "        'fr': \"Analyser le procès-verbal en français, sortie JSON stricte avec key_points en tableaux\"\n",
        "    }\n",
        "    lang_instruction = lang_map.get(language[:2], lang_map['zh'])\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=MeetingAnalysis)\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        {lang_instruction}\n",
        "\n",
        "        {format_instructions}\n",
        "\n",
        "        ### 会议记录:\n",
        "        {transcript}\n",
        "\n",
        "        请严格按照格式要求输出，确保JSON结构正确。\n",
        "        \"\"\",\n",
        "        input_variables=[\"transcript\"],\n",
        "        partial_variables={\n",
        "            \"lang_instruction\": lang_instruction,\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        temperature=0.3,\n",
        "        model=\"gpt-3.5-turbo\"\n",
        "    )\n",
        "\n",
        "    # 使用新的链式结构\n",
        "    analysis_chain = prompt_template | llm | parser\n",
        "\n",
        "    return analysis_chain\n",
        "\n",
        "def analyze_meeting(transcript, language='zh'):\n",
        "    logger.log_step(\"分析会议\", \"started\", {\"语言\": language})\n",
        "    print(\"\\n开始分析会议内容...\")\n",
        "\n",
        "    try:\n",
        "        analysis_chain = setup_langchain_chains(language)\n",
        "        processed_transcript = transcript[:15000]\n",
        "        print(f\"使用的转录文本长度: {len(processed_transcript)}字符\")\n",
        "\n",
        "        parsed = analysis_chain.invoke({\"transcript\": processed_transcript})\n",
        "\n",
        "        parsed[\"language\"] = language\n",
        "        parsed[\"date\"] = datetime.datetime.now().isoformat()\n",
        "\n",
        "        if not parsed.get(\"action_items\"):\n",
        "            logger.log_step(\"检查行动项\", \"warning\", \"未检测到行动项\")\n",
        "            print(\"⚠️ 未检测到行动项\")\n",
        "            parsed[\"fallback_used\"] = True\n",
        "        else:\n",
        "            parsed[\"fallback_used\"] = False\n",
        "\n",
        "        logger.log_step(\"分析会议\", \"success\", {\n",
        "            \"标题\": parsed[\"meeting_title\"],\n",
        "            \"参与者数量\": len(parsed[\"participants\"]),\n",
        "            \"行动项数量\": len(parsed[\"action_items\"])\n",
        "        })\n",
        "        print(f\"✅ 会议分析完成 (标题: {parsed['meeting_title']})\")\n",
        "        return parsed\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"分析会议失败: {str(e)}\"\n",
        "        logger.log_step(\"分析会议\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}\")\n",
        "        return {\"error\": error_msg, \"fallback_used\": True}\n",
        "\n",
        "# ======================\n",
        "# Notion报告生成\n",
        "# ======================\n",
        "def create_notion_report_page(meeting_data, transcript, logs):\n",
        "    logger.log_step(\"创建Notion报告\", \"started\")\n",
        "\n",
        "    try:\n",
        "        global notion\n",
        "\n",
        "        # 验证父页面\n",
        "        try:\n",
        "            parent_page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "            page_title = parent_page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题')\n",
        "            logger.log_step(\"父页面检查\", \"success\", {\"页面ID\": NOTION_PAGE_ID, \"标题\": page_title})\n",
        "            print(f\"✅ 成功访问父页面: {page_title} (ID: {NOTION_PAGE_ID[:8]}...)\")\n",
        "        except errors.APIResponseError as e:\n",
        "            if e.status == 404:\n",
        "                error_msg = f\"父页面不存在 (ID: {NOTION_PAGE_ID})。请检查ID是否正确。\"\n",
        "            elif e.status == 403:\n",
        "                error_msg = f\"没有访问父页面的权限 (ID: {NOTION_PAGE_ID})。请将页面共享给Notion集成。\"\n",
        "            else:\n",
        "                error_msg = f\"访问父页面失败: {str(e)}\"\n",
        "            logger.log_step(\"父页面检查\", \"failed\", error=error_msg)\n",
        "            print(f\"❌ {error_msg}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            error_msg = f\"父页面检查出错: {str(e)}\"\n",
        "            logger.log_step(\"父页面检查\", \"failed\", error=error_msg)\n",
        "            print(f\"❌ {error_msg}\")\n",
        "            return None\n",
        "\n",
        "        # 创建子页面\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"page_id\": NOTION_PAGE_ID},\n",
        "            properties={\n",
        "                \"title\": {\n",
        "                    \"title\": [\n",
        "                        {\n",
        "                            \"text\": {\n",
        "                                \"content\": meeting_data.get(\"meeting_title\", \"会议报告\")[:200]\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "        page_id = new_page[\"id\"]\n",
        "        logger.log_step(\"创建子页面\", \"success\", {\"页面ID\": page_id})\n",
        "        print(f\"✅ 已创建子页面 (ID: {page_id[:8]}...)\")\n",
        "\n",
        "        # 构建报告内容\n",
        "        children_blocks = []\n",
        "\n",
        "        # 1. 会议详情\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议详情\"}}]}\n",
        "        })\n",
        "\n",
        "        details_text = f\"\"\"\n",
        "        **日期**: {meeting_data.get('date', '未知')}\n",
        "        **参与者**: {', '.join(meeting_data.get('participants', []))}\n",
        "        **语言**: {meeting_data.get('language', '未知')}\n",
        "        **平台**: {meeting_data.get('platform', '未知')}\n",
        "        **会议类型**: {meeting_data.get('meeting_type', '未知')}\n",
        "        \"\"\"\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": details_text.strip()}}]}\n",
        "        })\n",
        "\n",
        "        # 2. 会议总结\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"总结\"}}]}\n",
        "        })\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get('summary', '')}}]}\n",
        "        })\n",
        "\n",
        "        # 3. 关键点（修复嵌套结构问题）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"关键点\"}}]}\n",
        "        })\n",
        "\n",
        "        key_points = meeting_data.get('key_points', {})\n",
        "        key_points = flatten_key_points(key_points)\n",
        "\n",
        "        for category, items in key_points.items():\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"heading_3\",\n",
        "                \"heading_3\": {\"rich_text\": [{\"text\": {\"content\": category.capitalize()}}]}\n",
        "            })\n",
        "\n",
        "            if items:\n",
        "                for item in items:\n",
        "                    children_blocks.append({\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"bulleted_list_item\",\n",
        "                        \"bulleted_list_item\": {\"rich_text\": [{\"text\": {\"content\": item}}]}\n",
        "                    })\n",
        "\n",
        "        # 4. 行动项\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"行动项\"}}]}\n",
        "        })\n",
        "\n",
        "        table_rows = []\n",
        "        for idx, item in enumerate(meeting_data.get('action_items', [])):\n",
        "            task = item.get('task', '')\n",
        "            assignee = item.get('assignee', '未分配')\n",
        "            due_date = item.get('due_date', '无')\n",
        "\n",
        "            table_rows.append([\n",
        "                [{\"text\": {\"content\": str(idx+1)}}],\n",
        "                [{\"text\": {\"content\": task}}],\n",
        "                [{\"text\": {\"content\": assignee}}],\n",
        "                [{\"text\": {\"content\": due_date}}]\n",
        "            ])\n",
        "\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"table\",\n",
        "            \"table\": {\n",
        "                \"table_width\": 4,\n",
        "                \"has_column_header\": True,\n",
        "                \"has_row_header\": False,\n",
        "                \"children\": [\n",
        "                    {\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\n",
        "                            \"cells\": [\n",
        "                                [{\"text\": {\"content\": \"序号\"}}],\n",
        "                                [{\"text\": {\"content\": \"任务\"}}],\n",
        "                                [{\"text\": {\"content\": \"负责人\"}}],\n",
        "                                [{\"text\": {\"content\": \"截止日期\"}}]\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    *[{\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\"cells\": cells}\n",
        "                    } for cells in table_rows]\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 5. 处理日志\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"处理日志\"}}]}\n",
        "        })\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"code\",\n",
        "            \"code\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": logger.get_console_log()}}],\n",
        "                \"language\": \"plain text\"\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 添加内容到页面\n",
        "        notion.blocks.children.append(\n",
        "            block_id=page_id,\n",
        "            children=children_blocks\n",
        "        )\n",
        "        logger.log_step(\"添加内容到页面\", \"success\")\n",
        "        print(f\"✅ 已添加内容到子页面\")\n",
        "\n",
        "\n",
        "        # 关联数据库（修改后）\n",
        "        if NOTION_DB_ID:\n",
        "            try:\n",
        "                db = notion.databases.retrieve(NOTION_DB_ID)\n",
        "                logger.log_step(\"数据库验证\", \"success\", {\"db_id\": NOTION_DB_ID})\n",
        "\n",
        "        # 手动指定你的关系属性名称\n",
        "                relation_prop_name = \"relation\"\n",
        "\n",
        "        # 验证属性\n",
        "                if relation_prop_name not in db[\"properties\"]:\n",
        "                    raise ValueError(f\"数据库中不存在名为「{relation_prop_name}」的属性\")\n",
        "                if db[\"properties\"][relation_prop_name][\"type\"] != \"relation\":\n",
        "                    raise ValueError(f\"属性「{relation_prop_name}」不是关系类型\")\n",
        "\n",
        "        # 关联\n",
        "                notion.pages.update(\n",
        "            page_id=page_id,\n",
        "            properties={\n",
        "                relation_prop_name: {\n",
        "                    \"relation\": [{\"id\": NOTION_DB_ID}]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "                logger.log_step(\"关联数据库\", \"success\", {\"使用的属性\": relation_prop_name})\n",
        "                print(f\"✅ 已通过属性「{relation_prop_name}」关联到数据库\")\n",
        "            except Exception as e:\n",
        "                logger.log_step(\"关联数据库\", \"warning\", error=str(e))\n",
        "                print(f\"⚠️ 关联数据库失败: {str(e)}（不影响报告生成）\")\n",
        "\n",
        "        report_url = new_page.get(\"url\", \"\")\n",
        "        logger.log_step(\"生成Notion报告\", \"success\", {\"URL\": report_url})\n",
        "        return report_url\n",
        "\n",
        "    except Exception as e:\n",
        "        error_details = f\"Notion API错误: {str(e)}\"\n",
        "        if hasattr(e, 'response') and hasattr(e.response, 'content'):\n",
        "            error_details += f\"\\n响应: {e.response.content.decode('utf-8')}\"\n",
        "        logger.log_step(\"生成Notion报告\", \"failed\", error=error_details)\n",
        "        print(f\"❌ Notion操作失败: {error_details}\")\n",
        "        return None\n",
        "\n",
        "# ======================\n",
        "# 权限测试函数\n",
        "# ======================\n",
        "def test_notion_permissions():\n",
        "    print(\"\\n=== 开始Notion权限测试 ===\")\n",
        "    print(f\"使用的父页面ID: {NOTION_PAGE_ID[:8]}... (完整: {NOTION_PAGE_ID})\")\n",
        "\n",
        "    # 1. 测试集成令牌有效性\n",
        "    try:\n",
        "        user_info = notion.users.me()\n",
        "        print(f\"✅ 集成令牌有效 (所属工作空间: {user_info.get('workspace_name', '未知')})\")\n",
        "    except errors.UnauthorizedError:\n",
        "        print(f\"❌ 集成令牌无效 (NOTION_TOKEN错误)\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 验证集成令牌时出错: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    # 2. 测试父页面访问权限\n",
        "    try:\n",
        "        page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "        page_title = page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题')\n",
        "        print(f\"✅ 成功访问父页面: {page_title}\")\n",
        "    except errors.APIResponseError as e:\n",
        "        if e.status == 404:\n",
        "            print(f\"❌ 父页面不存在 (ID错误或页面已删除)\")\n",
        "            return False\n",
        "        elif e.status == 403:\n",
        "            print(f\"❌ 没有访问权限 (请将页面共享给集成)\")\n",
        "            return False\n",
        "        else:\n",
        "            print(f\"❌ 访问页面时出错 (状态码: {e.status}): {str(e)}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 访问页面时发生未知错误: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    # 3. 测试数据库访问权限\n",
        "    try:\n",
        "        if NOTION_DB_ID:\n",
        "            db = notion.databases.retrieve(NOTION_DB_ID)\n",
        "            print(f\"✅ 成功访问数据库: {db.get('title', [{}])[0].get('plain_text', '无标题')}\")\n",
        "    except errors.APIResponseError as e:\n",
        "        print(f\"⚠️ 数据库访问警告: {str(e)}（仍可生成报告，但可能无法关联）\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# ======================\n",
        "# 输入处理\n",
        "# ======================\n",
        "def handle_transcript_input():\n",
        "    logger.log_step(\"处理输入\", \"started\")\n",
        "\n",
        "    print(\"\\n=== 输入方式选择 ===\")\n",
        "    print(\"1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\")\n",
        "    print(\"2: 上传文本文件 (.txt/.docx)\")\n",
        "    print(\"3: 直接粘贴文本\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"请选择输入方式 (1/2/3): \").strip() or \"1\"\n",
        "    except:\n",
        "        choice = \"1\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # 音频处理\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            logger.log_step(\"上传音频\", \"failed\", \"未上传任何文件\")\n",
        "            print(\"⚠️ 未上传文件，切换到文本输入\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        logger.log_step(\"上传音频\", \"success\", {\"文件名\": filename, \"大小\": len(uploaded[filename])})\n",
        "        print(f\"✅ 已上传音频文件: {filename}\")\n",
        "\n",
        "        ext = os.path.splitext(filename)[1].lower()\n",
        "        supported_audio = ['.mp3', '.wav', '.m4a', '.opus']\n",
        "        if ext not in supported_audio:\n",
        "            error = f\"不支持的音频格式: {ext} (支持: {', '.join(supported_audio)})\"\n",
        "            logger.log_step(\"处理音频\", \"failed\", error=error)\n",
        "            print(f\"❌ {error}\")\n",
        "            raise ValueError(error)\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:\n",
        "            tmp.write(uploaded[filename])\n",
        "            audio_path = tmp.name\n",
        "\n",
        "        # 选择模型\n",
        "        print(\"\\n⚡ 选择转录模型:\")\n",
        "        print(\"1: 快速 (tiny, 低精度)\")\n",
        "        print(\"2: 平衡 (base, 推荐)\")\n",
        "        print(\"3: 高精度 (small, 较慢)\")\n",
        "        try:\n",
        "            model_choice = input(\"请选择模型 (1/2/3): \").strip() or \"2\"\n",
        "        except:\n",
        "            model_choice = \"2\"\n",
        "        model_map = {\"1\": \"tiny\", \"2\": \"base\", \"3\": \"small\"}\n",
        "        model_size = model_map.get(model_choice, \"base\")\n",
        "        print(f\"使用模型: {model_size}\")\n",
        "\n",
        "        # 转录\n",
        "        duration = get_audio_duration(audio_path)\n",
        "        print(f\"音频时长: {duration:.1f}秒，开始转录...\")\n",
        "        transcript, detected_lang = transcribe_audio(audio_path, model_size)\n",
        "        os.unlink(audio_path)\n",
        "\n",
        "        print(f\"✅ 转录完成 (语言: {detected_lang})\")\n",
        "        return transcript, detected_lang\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        # 文本文件\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            logger.log_step(\"上传文本\", \"failed\", \"未上传任何文件\")\n",
        "            print(\"⚠️ 未上传文件，切换到直接粘贴\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        logger.log_step(\"上传文本\", \"success\", {\"文件名\": filename})\n",
        "        print(f\"✅ 已上传文件: {filename}\")\n",
        "\n",
        "        try:\n",
        "            if filename.endswith('.txt'):\n",
        "                transcript = uploaded[filename].decode('utf-8')\n",
        "            elif filename.endswith('.docx'):\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:\n",
        "                    tmp.write(uploaded[filename])\n",
        "                    doc = Document(tmp.name)\n",
        "                    transcript = \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "                    os.unlink(tmp.name)\n",
        "            else:\n",
        "                raise ValueError(f\"不支持的文件格式: {filename} (支持: .txt, .docx)\")\n",
        "\n",
        "            # 检测语言\n",
        "            lang = detect(transcript[:500]) if transcript else 'zh'\n",
        "            logger.log_step(\"检测语言\", \"success\", {\"语言\": lang})\n",
        "            print(f\"✅ 读取完成 (检测语言: {lang})\")\n",
        "            return transcript, lang\n",
        "        except Exception as e:\n",
        "            logger.log_step(\"处理文本文件\", \"failed\", error=str(e))\n",
        "            print(f\"❌ 处理文件出错: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        # 直接粘贴\n",
        "        print(\"\\n请粘贴会议记录 (粘贴后按Enter，输入空行结束):\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if not line:\n",
        "                break\n",
        "            lines.append(line)\n",
        "        transcript = \"\\n\".join(lines)\n",
        "\n",
        "        if not transcript.strip():\n",
        "            logger.log_step(\"输入文本\", \"failed\", \"未输入任何内容\")\n",
        "            print(\"⚠️ 未输入任何内容，重新选择输入方式\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        # 检测语言\n",
        "        try:\n",
        "            lang = detect(transcript[:500])\n",
        "            logger.log_step(\"检测语言\", \"success\", {\"语言\": lang})\n",
        "            print(f\"✅ 已输入文本 (检测语言: {lang})\")\n",
        "        except:\n",
        "            lang = 'zh'\n",
        "            logger.log_step(\"检测语言\", \"warning\", \"使用默认语言中文\")\n",
        "            print(f\"✅ 已输入文本 (使用默认语言: 中文)\")\n",
        "\n",
        "        return transcript, lang\n",
        "\n",
        "    else:\n",
        "        logger.log_step(\"选择输入方式\", \"warning\", \"无效选择，使用默认音频输入\")\n",
        "        print(\"⚠️ 无效选择，默认使用音频输入\")\n",
        "        return handle_transcript_input()\n",
        "\n",
        "# ======================\n",
        "# 主函数\n",
        "# ======================\n",
        "def main():\n",
        "    logger.log_step(\"工作流程\", \"started\")\n",
        "    print(\"=== 会议记录处理工具 ===\")\n",
        "\n",
        "    try:\n",
        "        if not test_notion_permissions():\n",
        "            print(\"\\n❌ 权限测试未通过，请先解决上述问题\")\n",
        "            log_file = logger.save_logs(\"error_logs.json\")\n",
        "            print(f\"错误日志已保存到: {log_file}\")\n",
        "            return\n",
        "\n",
        "        transcript, language = handle_transcript_input()\n",
        "        logger.log_metric(\"转录文本长度\", len(transcript))\n",
        "\n",
        "        meeting_data = analyze_meeting(transcript, language)\n",
        "        if \"error\" in meeting_data:\n",
        "            raise RuntimeError(f\"分析失败: {meeting_data['error']}\")\n",
        "\n",
        "        print(\"\\n开始创建Notion报告...\")\n",
        "        report_url = create_notion_report_page(meeting_data, transcript, logger.logs)\n",
        "\n",
        "        if not report_url:\n",
        "            raise RuntimeError(\"创建Notion报告失败\")\n",
        "\n",
        "        log_file = logger.save_logs()\n",
        "        print(f\"\\n🎉 处理完成！\")\n",
        "        print(f\"📄 会议报告URL: {report_url}\")\n",
        "        print(f\"📋 日志文件: {log_file}\")\n",
        "\n",
        "        from IPython.display import HTML\n",
        "        display(HTML(f'<a href=\"{report_url}\" target=\"_blank\">点击打开Notion报告</a>'))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"工作流程\", \"failed\", error=str(e))\n",
        "        log_file = logger.save_logs(\"error_logs.json\")\n",
        "        print(f\"\\n❌ 处理失败！\")\n",
        "        print(f\"错误详情: {str(e)}\")\n",
        "        print(f\"错误日志已保存到: {log_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装依赖 - 修改部分\n",
        "!pip uninstall -y whisper\n",
        "!pip install faster-whisper\n",
        "!pip install git+https://github.com/openai/whisper.git  # 保留原接口但使用faster-whisper后端\n",
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import openai\n",
        "import whisper\n",
        "from docx import Document\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client, errors\n",
        "from langdetect import detect, LangDetectException\n",
        "import datetime\n",
        "import tempfile\n",
        "import torch\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "import httpx\n",
        "from whisper.utils import get_writer  # 导入faster-whisper的辅助工具\n",
        "# 清除代理环境变量\n",
        "for var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:\n",
        "    if var in os.environ:\n",
        "        del os.environ[var]\n",
        "# 初始化Notion客户端\n",
        "http_client = httpx.Client()\n",
        "http_client.proxies = None  # 禁用代理\n",
        "\n",
        "notion = Client(\n",
        "    auth=userdata.get('NOTION_TOKEN'),\n",
        "    client=http_client\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 初始化设置\n",
        "# ======================\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_DB_ID = userdata.get('NOTION_DB_ID')\n",
        "    NOTION_PAGE_ID = userdata.get('NOTION_PAGE_ID')\n",
        "\n",
        "    missing_creds = []\n",
        "    if not OPENAI_API_KEY:\n",
        "        missing_creds.append(\"OPENAI_API_KEY\")\n",
        "    if not NOTION_TOKEN:\n",
        "        missing_creds.append(\"NOTION_TOKEN\")\n",
        "    if not NOTION_DB_ID:\n",
        "        missing_creds.append(\"NOTION_DB_ID\")\n",
        "    if not NOTION_PAGE_ID:\n",
        "        missing_creds.append(\"NOTION_PAGE_ID\")\n",
        "\n",
        "    if missing_creds:\n",
        "        raise ValueError(f\"缺少凭证: {', '.join(missing_creds)}\")\n",
        "\n",
        "    print(\"✅ 所有凭证已设置\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 凭证获取失败: {str(e)}\")\n",
        "    print(\"\\n🔧 设置说明:\")\n",
        "    print(\"1. 点击左侧边栏的钥匙图标（Colab密钥）\")\n",
        "    print(\"2. 添加以下密钥:\")\n",
        "    print(\"   - OPENAI_API_KEY: 你的OpenAI API密钥\")\n",
        "    print(\"   - NOTION_TOKEN: 你的Notion集成令牌\")\n",
        "    print(\"   - NOTION_DB_ID: Notion数据库ID\")\n",
        "    print(\"   - NOTION_PAGE_ID: 报告父页面ID\")\n",
        "    print(\"3. 添加后重新运行此单元格\")\n",
        "    raise\n",
        "\n",
        "# ======================\n",
        "# 日志系统\n",
        "# ======================\n",
        "class MeetingLogger:\n",
        "    def __init__(self):\n",
        "        self.logs = {\n",
        "            \"start_time\": datetime.datetime.now().isoformat(),\n",
        "            \"steps\": [],\n",
        "            \"errors\": [],\n",
        "            \"metrics\": {}\n",
        "        }\n",
        "\n",
        "    def log_step(self, step_name, status, details=None, error=None):\n",
        "        entry = {\n",
        "            \"step\": step_name,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"status\": status\n",
        "        }\n",
        "        if details:\n",
        "            entry[\"details\"] = details\n",
        "        if error:\n",
        "            entry[\"error\"] = str(error)\n",
        "        self.logs[\"steps\"].append(entry)\n",
        "\n",
        "    def log_metric(self, name, value):\n",
        "        self.logs[\"metrics\"][name] = value\n",
        "\n",
        "    def save_logs(self, filename=\"meeting_logs.json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(self.logs, f, indent=2)\n",
        "        return filename\n",
        "\n",
        "    def get_console_log(self):\n",
        "        log_str = f\"=== 会议处理日志 ===\\n\"\n",
        "        log_str += f\"开始时间: {self.logs['start_time']}\\n\"\n",
        "\n",
        "        for step in self.logs[\"steps\"]:\n",
        "            status_icon = \"✅\" if step[\"status\"] == \"success\" else \"❌\"\n",
        "            log_str += f\"{status_icon} [{step['timestamp']}] {step['step']}\"\n",
        "            if \"details\" in step:\n",
        "                log_str += f\" - {step['details']}\"\n",
        "            if step[\"status\"] == \"failed\":\n",
        "                log_str += f\" - 错误: {step.get('error', '未知')}\"\n",
        "            log_str += \"\\n\"\n",
        "\n",
        "        if self.logs[\"metrics\"]:\n",
        "            log_str += \"\\n=== 指标 ===\\n\"\n",
        "            for metric, value in self.logs[\"metrics\"].items():\n",
        "                log_str += f\"- {metric}: {value}\\n\"\n",
        "\n",
        "        return log_str\n",
        "\n",
        "logger = MeetingLogger()\n",
        "\n",
        "# ======================\n",
        "# 工具函数：处理嵌套结构\n",
        "# ======================\n",
        "def flatten_key_points(key_points):\n",
        "    \"\"\"将key_points中的嵌套结构（字典/列表）转换为字符串，适配Notion格式\"\"\"\n",
        "    flattened = {}\n",
        "    for category, items in key_points.items():\n",
        "        flattened_items = []\n",
        "        for item in items:\n",
        "            # 处理字典类型（如{\"部门\": [\"问题1\", \"问题2\"]}）\n",
        "            if isinstance(item, dict):\n",
        "                dict_strings = []\n",
        "                for k, v in item.items():\n",
        "                    # 字典的值如果是列表，转换为带符号的字符串\n",
        "                    if isinstance(v, list):\n",
        "                        list_str = \"• \".join([str(i) for i in v])\n",
        "                        dict_strings.append(f\"{k}：• {list_str}\")\n",
        "                    else:\n",
        "                        dict_strings.append(f\"{k}：{v}\")\n",
        "                flattened_items.append(\"； \".join(dict_strings))\n",
        "\n",
        "            # 处理列表类型（如[\"问题1\", \"问题2\"]）\n",
        "            elif isinstance(item, list):\n",
        "                list_str = \"• \".join([str(i) for i in item])\n",
        "                flattened_items.append(f\"• {list_str}\")\n",
        "\n",
        "            # 字符串直接保留\n",
        "            else:\n",
        "                flattened_items.append(str(item))\n",
        "        flattened[category] = flattened_items\n",
        "    return flattened\n",
        "\n",
        "# ======================\n",
        "# 音频处理 - 修改部分\n",
        "# ======================\n",
        "def transcribe_audio(audio_path, model_size=\"base\"):\n",
        "    logger.log_step(\"音频转录\", \"started\", {\"模型大小\": model_size, \"音频路径\": audio_path})\n",
        "\n",
        "    try:\n",
        "        # 使用faster-whisper进行转录\n",
        "        from faster_whisper import WhisperModel\n",
        "\n",
        "        # 根据GPU可用性选择计算设备\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "\n",
        "        logger.log_step(\"加载faster-whisper模型\", \"info\", {\n",
        "            \"设备\": device,\n",
        "            \"计算类型\": compute_type,\n",
        "            \"模型大小\": model_size\n",
        "        })\n",
        "\n",
        "        # 加载模型 - 使用本地缓存避免重复下载\n",
        "        model = WhisperModel(\n",
        "            model_size,\n",
        "            device=device,\n",
        "            compute_type=compute_type,\n",
        "            download_root=\"/content/models\"  # 设置模型缓存目录\n",
        "        )\n",
        "\n",
        "        # 执行转录\n",
        "        logger.log_step(\"开始转录\", \"processing\")\n",
        "        segments, info = model.transcribe(\n",
        "            audio_path,\n",
        "            beam_size=5,  # 平衡速度和准确度\n",
        "            vad_filter=True,  # 启用语音活动检测\n",
        "            word_timestamps=False  # 不需要单词级时间戳\n",
        "        )\n",
        "\n",
        "        # 检测语言\n",
        "        detected_lang = info.language\n",
        "        logger.log_step(\"语言检测\", \"success\", {\"语言\": detected_lang})\n",
        "\n",
        "        # 收集转录文本\n",
        "        transcription = \"\"\n",
        "        segment_list = []\n",
        "\n",
        "        # 使用进度条显示转录过程\n",
        "        with tqdm(total=info.duration, unit='sec', desc=\"转录进度\") as pbar:\n",
        "            for segment in segments:\n",
        "                segment_list.append(segment.text)\n",
        "                pbar.update(segment.end - pbar.n)\n",
        "\n",
        "        transcription = \" \".join(segment_list)\n",
        "\n",
        "        logger.log_step(\"音频转录\", \"success\", {\n",
        "            \"字符数\": len(transcription),\n",
        "            \"检测语言\": detected_lang,\n",
        "            \"音频时长\": f\"{info.duration:.2f}秒\"\n",
        "        })\n",
        "\n",
        "        return transcription, detected_lang\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频转录\", \"failed\", error=e)\n",
        "        # 回退到原始whisper\n",
        "        logger.log_step(\"尝试使用原始whisper\", \"fallback\")\n",
        "        try:\n",
        "            model = whisper.load_model(model_size)\n",
        "            result = model.transcribe(audio_path)\n",
        "            return result[\"text\"], result[\"language\"]\n",
        "        except Exception as fallback_error:\n",
        "            logger.log_step(\"原始whisper回退失败\", \"failed\", error=fallback_error)\n",
        "            raise RuntimeError(f\"转录失败: {str(e)} | 回退失败: {str(fallback_error)}\")\n",
        "# ======================\n",
        "# 会议分析模型与处理\n",
        "# ======================\n",
        "class MeetingAnalysis(BaseModel):\n",
        "    meeting_title: str = Field(description=\"会议标题\")\n",
        "    participants: list[str] = Field(description=\"参与者名单\")\n",
        "    summary: str = Field(description=\"3-5段会议总结\")\n",
        "    key_points: dict = Field(description=\"按concerns、decisions、updates、risks分组的关键点（均为数组）\")\n",
        "    action_items: list[dict] = Field(description=\"行动项列表，包含task、assignee、due_date\")\n",
        "    meeting_type: str = Field(description=\"会议类型\")\n",
        "    platform: str = Field(description=\"会议平台\")\n",
        "\n",
        "def setup_langchain_chains(language='zh'):\n",
        "    lang_map = {\n",
        "        'zh': \"用中文分析会议记录，输出严格符合JSON格式，key_points的子字段均为数组（用[]包裹）\",\n",
        "        'en': \"Analyze the meeting transcript in English, output strict JSON with key_points as arrays\",\n",
        "        'fr': \"Analyser le procès-verbal en français, sortie JSON stricte avec key_points en tableaux\"\n",
        "    }\n",
        "    lang_instruction = lang_map.get(language[:2], lang_map['zh'])\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=MeetingAnalysis)\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        {lang_instruction}\n",
        "\n",
        "        {format_instructions}\n",
        "\n",
        "        ### 会议记录:\n",
        "        {transcript}\n",
        "\n",
        "        请严格按照格式要求输出，确保JSON结构正确。\n",
        "        \"\"\",\n",
        "        input_variables=[\"transcript\"],\n",
        "        partial_variables={\n",
        "            \"lang_instruction\": lang_instruction,\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        temperature=0.3,\n",
        "        model=\"gpt-3.5-turbo\"\n",
        "    )\n",
        "\n",
        "    # 使用新的链式结构\n",
        "    analysis_chain = prompt_template | llm | parser\n",
        "\n",
        "    return analysis_chain\n",
        "\n",
        "def analyze_meeting(transcript, language='zh'):\n",
        "    logger.log_step(\"分析会议\", \"started\", {\"语言\": language})\n",
        "    print(\"\\n开始分析会议内容...\")\n",
        "\n",
        "    try:\n",
        "        analysis_chain = setup_langchain_chains(language)\n",
        "        processed_transcript = transcript[:15000]\n",
        "        print(f\"使用的转录文本长度: {len(processed_transcript)}字符\")\n",
        "\n",
        "        parsed = analysis_chain.invoke({\"transcript\": processed_transcript})\n",
        "\n",
        "        parsed[\"language\"] = language\n",
        "        parsed[\"date\"] = datetime.datetime.now().isoformat()\n",
        "\n",
        "        if not parsed.get(\"action_items\"):\n",
        "            logger.log_step(\"检查行动项\", \"warning\", \"未检测到行动项\")\n",
        "            print(\"⚠️ 未检测到行动项\")\n",
        "            parsed[\"fallback_used\"] = True\n",
        "        else:\n",
        "            parsed[\"fallback_used\"] = False\n",
        "\n",
        "        logger.log_step(\"分析会议\", \"success\", {\n",
        "            \"标题\": parsed[\"meeting_title\"],\n",
        "            \"参与者数量\": len(parsed[\"participants\"]),\n",
        "            \"行动项数量\": len(parsed[\"action_items\"])\n",
        "        })\n",
        "        print(f\"✅ 会议分析完成 (标题: {parsed['meeting_title']})\")\n",
        "        return parsed\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"分析会议失败: {str(e)}\"\n",
        "        logger.log_step(\"分析会议\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}\")\n",
        "        return {\"error\": error_msg, \"fallback_used\": True}\n",
        "\n",
        "# ======================\n",
        "# Notion报告生成\n",
        "# ======================\n",
        "def create_notion_report_page(meeting_data, transcript, logs):\n",
        "    logger.log_step(\"创建Notion报告\", \"started\")\n",
        "\n",
        "    try:\n",
        "        global notion\n",
        "\n",
        "        # 验证父页面\n",
        "        try:\n",
        "            parent_page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "            page_title = parent_page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题')\n",
        "            logger.log_step(\"父页面检查\", \"success\", {\"页面ID\": NOTION_PAGE_ID, \"标题\": page_title})\n",
        "            print(f\"✅ 成功访问父页面: {page_title} (ID: {NOTION_PAGE_ID[:8]}...)\")\n",
        "        except errors.APIResponseError as e:\n",
        "            if e.status == 404:\n",
        "                error_msg = f\"父页面不存在 (ID: {NOTION_PAGE_ID})。请检查ID是否正确。\"\n",
        "            elif e.status == 403:\n",
        "                error_msg = f\"没有访问父页面的权限 (ID: {NOTION_PAGE_ID})。请将页面共享给Notion集成。\"\n",
        "            else:\n",
        "                error_msg = f\"访问父页面失败: {str(e)}\"\n",
        "            logger.log_step(\"父页面检查\", \"failed\", error=error_msg)\n",
        "            print(f\"❌ {error_msg}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            error_msg = f\"父页面检查出错: {str(e)}\"\n",
        "            logger.log_step(\"父页面检查\", \"failed\", error=error_msg)\n",
        "            print(f\"❌ {error_msg}\")\n",
        "            return None\n",
        "\n",
        "        # 创建子页面\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"page_id\": NOTION_PAGE_ID},\n",
        "            properties={\n",
        "                \"title\": {\n",
        "                    \"title\": [\n",
        "                        {\n",
        "                            \"text\": {\n",
        "                                \"content\": meeting_data.get(\"meeting_title\", \"会议报告\")[:200]\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "        page_id = new_page[\"id\"]\n",
        "        logger.log_step(\"创建子页面\", \"success\", {\"页面ID\": page_id})\n",
        "        print(f\"✅ 已创建子页面 (ID: {page_id[:8]}...)\")\n",
        "\n",
        "        # 构建报告内容\n",
        "        children_blocks = []\n",
        "\n",
        "        # 1. 会议详情\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议详情\"}}]}\n",
        "        })\n",
        "\n",
        "        details_text = f\"\"\"\n",
        "        **日期**: {meeting_data.get('date', '未知')}\n",
        "        **参与者**: {', '.join(meeting_data.get('participants', []))}\n",
        "        **语言**: {meeting_data.get('language', '未知')}\n",
        "        **平台**: {meeting_data.get('platform', '未知')}\n",
        "        **会议类型**: {meeting_data.get('meeting_type', '未知')}\n",
        "        \"\"\"\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": details_text.strip()}}]}\n",
        "        })\n",
        "\n",
        "        # 2. 会议总结\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"总结\"}}]}\n",
        "        })\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": meeting_data.get('summary', '')}}]}\n",
        "        })\n",
        "\n",
        "        # 3. 关键点（修复嵌套结构问题）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"关键点\"}}]}\n",
        "        })\n",
        "\n",
        "        key_points = meeting_data.get('key_points', {})\n",
        "        key_points = flatten_key_points(key_points)\n",
        "\n",
        "        for category, items in key_points.items():\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"heading_3\",\n",
        "                \"heading_3\": {\"rich_text\": [{\"text\": {\"content\": category.capitalize()}}]}\n",
        "            })\n",
        "\n",
        "            if items:\n",
        "                for item in items:\n",
        "                    children_blocks.append({\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"bulleted_list_item\",\n",
        "                        \"bulleted_list_item\": {\"rich_text\": [{\"text\": {\"content\": item}}]}\n",
        "                    })\n",
        "\n",
        "        # 4. 行动项\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"行动项\"}}]}\n",
        "        })\n",
        "\n",
        "        table_rows = []\n",
        "        for idx, item in enumerate(meeting_data.get('action_items', [])):\n",
        "            task = item.get('task', '')\n",
        "            assignee = item.get('assignee', '未分配')\n",
        "            due_date = item.get('due_date', '无')\n",
        "\n",
        "            table_rows.append([\n",
        "                [{\"text\": {\"content\": str(idx+1)}}],\n",
        "                [{\"text\": {\"content\": task}}],\n",
        "                [{\"text\": {\"content\": assignee}}],\n",
        "                [{\"text\": {\"content\": due_date}}]\n",
        "            ])\n",
        "\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"table\",\n",
        "            \"table\": {\n",
        "                \"table_width\": 4,\n",
        "                \"has_column_header\": True,\n",
        "                \"has_row_header\": False,\n",
        "                \"children\": [\n",
        "                    {\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\n",
        "                            \"cells\": [\n",
        "                                [{\"text\": {\"content\": \"序号\"}}],\n",
        "                                [{\"text\": {\"content\": \"任务\"}}],\n",
        "                                [{\"text\": {\"content\": \"负责人\"}}],\n",
        "                                [{\"text\": {\"content\": \"截止日期\"}}]\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    *[{\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\"cells\": cells}\n",
        "                    } for cells in table_rows]\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 5. 处理日志\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"处理日志\"}}]}\n",
        "        })\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"code\",\n",
        "            \"code\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": logger.get_console_log()}}],\n",
        "                \"language\": \"plain text\"\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 添加内容到页面\n",
        "        notion.blocks.children.append(\n",
        "            block_id=page_id,\n",
        "            children=children_blocks\n",
        "        )\n",
        "        logger.log_step(\"添加内容到页面\", \"success\")\n",
        "        print(f\"✅ 已添加内容到子页面\")\n",
        "\n",
        "\n",
        "        # 关联数据库（修改后）\n",
        "        if NOTION_DB_ID:\n",
        "            try:\n",
        "                db = notion.databases.retrieve(NOTION_DB_ID)\n",
        "                logger.log_step(\"数据库验证\", \"success\", {\"db_id\": NOTION_DB_ID})\n",
        "\n",
        "        # 手动指定你的关系属性名称\n",
        "                relation_prop_name = \"relation\"\n",
        "\n",
        "        # 验证属性\n",
        "                if relation_prop_name not in db[\"properties\"]:\n",
        "                    raise ValueError(f\"数据库中不存在名为「{relation_prop_name}」的属性\")\n",
        "                if db[\"properties\"][relation_prop_name][\"type\"] != \"relation\":\n",
        "                    raise ValueError(f\"属性「{relation_prop_name}」不是关系类型\")\n",
        "\n",
        "        # 关联\n",
        "                notion.pages.update(\n",
        "            page_id=page_id,\n",
        "            properties={\n",
        "                relation_prop_name: {\n",
        "                    \"relation\": [{\"id\": NOTION_DB_ID}]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "                logger.log_step(\"关联数据库\", \"success\", {\"使用的属性\": relation_prop_name})\n",
        "                print(f\"✅ 已通过属性「{relation_prop_name}」关联到数据库\")\n",
        "            except Exception as e:\n",
        "                logger.log_step(\"关联数据库\", \"warning\", error=str(e))\n",
        "                print(f\"⚠️ 关联数据库失败: {str(e)}（不影响报告生成）\")\n",
        "\n",
        "        report_url = new_page.get(\"url\", \"\")\n",
        "        logger.log_step(\"生成Notion报告\", \"success\", {\"URL\": report_url})\n",
        "        return report_url\n",
        "\n",
        "    except Exception as e:\n",
        "        error_details = f\"Notion API错误: {str(e)}\"\n",
        "        if hasattr(e, 'response') and hasattr(e.response, 'content'):\n",
        "            error_details += f\"\\n响应: {e.response.content.decode('utf-8')}\"\n",
        "        logger.log_step(\"生成Notion报告\", \"failed\", error=error_details)\n",
        "        print(f\"❌ Notion操作失败: {error_details}\")\n",
        "        return None\n",
        "\n",
        "# ======================\n",
        "# 权限测试函数\n",
        "# ======================\n",
        "def test_notion_permissions():\n",
        "    print(\"\\n=== 开始Notion权限测试 ===\")\n",
        "    print(f\"使用的父页面ID: {NOTION_PAGE_ID[:8]}... (完整: {NOTION_PAGE_ID})\")\n",
        "\n",
        "    # 1. 测试集成令牌有效性\n",
        "    try:\n",
        "        user_info = notion.users.me()\n",
        "        print(f\"✅ 集成令牌有效 (所属工作空间: {user_info.get('workspace_name', '未知')})\")\n",
        "    except errors.UnauthorizedError:\n",
        "        print(f\"❌ 集成令牌无效 (NOTION_TOKEN错误)\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 验证集成令牌时出错: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    # 2. 测试父页面访问权限\n",
        "    try:\n",
        "        page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "        page_title = page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题')\n",
        "        print(f\"✅ 成功访问父页面: {page_title}\")\n",
        "    except errors.APIResponseError as e:\n",
        "        if e.status == 404:\n",
        "            print(f\"❌ 父页面不存在 (ID错误或页面已删除)\")\n",
        "            return False\n",
        "        elif e.status == 403:\n",
        "            print(f\"❌ 没有访问权限 (请将页面共享给集成)\")\n",
        "            return False\n",
        "        else:\n",
        "            print(f\"❌ 访问页面时出错 (状态码: {e.status}): {str(e)}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 访问页面时发生未知错误: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    # 3. 测试数据库访问权限\n",
        "    try:\n",
        "        if NOTION_DB_ID:\n",
        "            db = notion.databases.retrieve(NOTION_DB_ID)\n",
        "            print(f\"✅ 成功访问数据库: {db.get('title', [{}])[0].get('plain_text', '无标题')}\")\n",
        "    except errors.APIResponseError as e:\n",
        "        print(f\"⚠️ 数据库访问警告: {str(e)}（仍可生成报告，但可能无法关联）\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# ======================\n",
        "# 输入处理\n",
        "# ======================\n",
        "# 在 handle_transcript_input 函数中添加缺失的音频上传代码\n",
        "def handle_transcript_input():\n",
        "    logger.log_step(\"处理输入\", \"started\")\n",
        "\n",
        "    print(\"\\n=== 输入方式选择 ===\")\n",
        "    print(\"1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\")\n",
        "    print(\"2: 上传文本文件 (.txt/.docx)\")\n",
        "    print(\"3: 直接粘贴文本\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"请选择输入方式 (1/2/3): \").strip() or \"1\"\n",
        "    except:\n",
        "        choice = \"1\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # === 添加的音频上传代码开始 ===\n",
        "        print(\"\\n请上传音频文件 (支持.mp3/.wav/.m4a/.opus):\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            logger.log_step(\"上传音频\", \"failed\", \"未上传任何文件\")\n",
        "            print(\"⚠️ 未上传文件，请重新选择输入方式\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        audio_ext = os.path.splitext(filename)[1].lower()\n",
        "        if audio_ext not in ['.mp3', '.wav', '.m4a', '.opus']:\n",
        "            logger.log_step(\"上传音频\", \"failed\", f\"不支持的文件格式: {filename}\")\n",
        "            print(f\"❌ 不支持的文件格式: {filename} (请上传.mp3/.wav/.m4a/.opus)\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        # 保存上传的音频文件\n",
        "        audio_path = f\"/tmp/{filename}\"\n",
        "        with open(audio_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "        logger.log_step(\"上传音频\", \"success\", {\"文件名\": filename, \"路径\": audio_path})\n",
        "        print(f\"✅ 已上传音频: {filename}\")\n",
        "        # === 添加的音频上传代码结束 ===\n",
        "\n",
        "        # 增强模型选择\n",
        "        print(\"\\n⚡ 选择转录模型 (使用faster-whisper):\")\n",
        "        print(\"1: 极速 (tiny, 最快但精度较低)\")\n",
        "        print(\"2: 快速 (base, 推荐日常使用)\")\n",
        "        print(\"3: 平衡 (small, 速度和精度平衡)\")\n",
        "        print(\"4: 高精度 (medium, 会议记录推荐)\")\n",
        "        print(\"5: 专业级 (large, 最高精度)\")\n",
        "\n",
        "        try:\n",
        "            model_choice = input(\"请选择模型 (1-5): \").strip() or \"4\"\n",
        "        except:\n",
        "            model_choice = \"4\"\n",
        "\n",
        "        model_map = {\n",
        "            \"1\": \"tiny\",\n",
        "            \"2\": \"base\",\n",
        "            \"3\": \"small\",\n",
        "            \"4\": \"medium\",\n",
        "            \"5\": \"large\"\n",
        "        }\n",
        "\n",
        "        model_size = model_map.get(model_choice, \"medium\")\n",
        "        print(f\"使用模型: {model_size}\")\n",
        "\n",
        "        # 获取音频时长\n",
        "        duration = get_audio_duration(audio_path)\n",
        "        print(f\"音频时长: {duration:.1f}秒，开始转录...\")\n",
        "\n",
        "        # 添加性能提示\n",
        "        if duration > 600:  # 超过10分钟\n",
        "            print(\"⏳ 较长音频处理中... 请耐心等待 (可使用Colab Pro获得GPU加速)\")\n",
        "        elif model_size in [\"medium\", \"large\"]:\n",
        "            print(\"🔍 使用高精度模型，可能需要更长时间...\")\n",
        "\n",
        "        transcript, detected_lang = transcribe_audio(audio_path, model_size)\n",
        "        os.unlink(audio_path)  # 删除临时文件\n",
        "\n",
        "        print(f\"✅ 转录完成 (语言: {detected_lang})\")\n",
        "        return transcript, detected_lang\n",
        "\n",
        "    # ... [其他输入方式的代码保持不变] ...\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        # 文本文件\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            logger.log_step(\"上传文本\", \"failed\", \"未上传任何文件\")\n",
        "            print(\"⚠️ 未上传文件，切换到直接粘贴\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        logger.log_step(\"上传文本\", \"success\", {\"文件名\": filename})\n",
        "        print(f\"✅ 已上传文件: {filename}\")\n",
        "\n",
        "        try:\n",
        "            if filename.endswith('.txt'):\n",
        "                transcript = uploaded[filename].decode('utf-8')\n",
        "            elif filename.endswith('.docx'):\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:\n",
        "                    tmp.write(uploaded[filename])\n",
        "                    doc = Document(tmp.name)\n",
        "                    transcript = \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "                    os.unlink(tmp.name)\n",
        "            else:\n",
        "                raise ValueError(f\"不支持的文件格式: {filename} (支持: .txt, .docx)\")\n",
        "\n",
        "            # 检测语言\n",
        "            lang = detect(transcript[:500]) if transcript else 'zh'\n",
        "            logger.log_step(\"检测语言\", \"success\", {\"语言\": lang})\n",
        "            print(f\"✅ 读取完成 (检测语言: {lang})\")\n",
        "            return transcript, lang\n",
        "        except Exception as e:\n",
        "            logger.log_step(\"处理文本文件\", \"failed\", error=str(e))\n",
        "            print(f\"❌ 处理文件出错: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        # 直接粘贴\n",
        "        print(\"\\n请粘贴会议记录 (粘贴后按Enter，输入空行结束):\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if not line:\n",
        "                break\n",
        "            lines.append(line)\n",
        "        transcript = \"\\n\".join(lines)\n",
        "\n",
        "        if not transcript.strip():\n",
        "            logger.log_step(\"输入文本\", \"failed\", \"未输入任何内容\")\n",
        "            print(\"⚠️ 未输入任何内容，重新选择输入方式\")\n",
        "            return handle_transcript_input()\n",
        "\n",
        "        # 检测语言\n",
        "        try:\n",
        "            lang = detect(transcript[:500])\n",
        "            logger.log_step(\"检测语言\", \"success\", {\"语言\": lang})\n",
        "            print(f\"✅ 已输入文本 (检测语言: {lang})\")\n",
        "        except:\n",
        "            lang = 'zh'\n",
        "            logger.log_step(\"检测语言\", \"warning\", \"使用默认语言中文\")\n",
        "            print(f\"✅ 已输入文本 (使用默认语言: 中文)\")\n",
        "\n",
        "        return transcript, lang\n",
        "\n",
        "    else:\n",
        "        logger.log_step(\"选择输入方式\", \"warning\", \"无效选择，使用默认音频输入\")\n",
        "        print(\"⚠️ 无效选择，默认使用音频输入\")\n",
        "        return handle_transcript_input()\n",
        "\n",
        "# ======================\n",
        "# 主函数\n",
        "# ======================\n",
        "def main():\n",
        "    logger.log_step(\"工作流程\", \"started\")\n",
        "    print(\"=== 会议记录处理工具 ===\")\n",
        "\n",
        "    try:\n",
        "        if not test_notion_permissions():\n",
        "            print(\"\\n❌ 权限测试未通过，请先解决上述问题\")\n",
        "            log_file = logger.save_logs(\"error_logs.json\")\n",
        "            print(f\"错误日志已保存到: {log_file}\")\n",
        "            return\n",
        "\n",
        "        transcript, language = handle_transcript_input()\n",
        "        logger.log_metric(\"转录文本长度\", len(transcript))\n",
        "\n",
        "        meeting_data = analyze_meeting(transcript, language)\n",
        "        if \"error\" in meeting_data:\n",
        "            raise RuntimeError(f\"分析失败: {meeting_data['error']}\")\n",
        "\n",
        "        print(\"\\n开始创建Notion报告...\")\n",
        "        report_url = create_notion_report_page(meeting_data, transcript, logger.logs)\n",
        "\n",
        "        if not report_url:\n",
        "            raise RuntimeError(\"创建Notion报告失败\")\n",
        "\n",
        "        log_file = logger.save_logs()\n",
        "        print(f\"\\n🎉 处理完成！\")\n",
        "        print(f\"📄 会议报告URL: {report_url}\")\n",
        "        print(f\"📋 日志文件: {log_file}\")\n",
        "\n",
        "        from IPython.display import HTML\n",
        "        display(HTML(f'<a href=\"{report_url}\" target=\"_blank\">点击打开Notion报告</a>'))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"工作流程\", \"failed\", error=str(e))\n",
        "        log_file = logger.save_logs(\"error_logs.json\")\n",
        "        print(f\"\\n❌ 处理失败！\")\n",
        "        print(f\"错误详情: {str(e)}\")\n",
        "        print(f\"错误日志已保存到: {log_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8ADRLMjnOY6e",
        "outputId": "aa5fcae5-df36-4c88-d843-1282fbe04400",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.22.1)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (15.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (6.31.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-39ariy6n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-39ariy6n\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper==20250625) (8.10.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.61.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.7.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "3 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n",
            "✅ 所有凭证已设置\n",
            "=== 会议记录处理工具 ===\n",
            "\n",
            "=== 开始Notion权限测试 ===\n",
            "使用的父页面ID: 2335fee1... (完整: 2335fee18e378097a863fff646e8b48c)\n",
            "✅ 集成令牌有效 (所属工作空间: 未知)\n",
            "✅ 成功访问父页面: Parent Page\n",
            "✅ 成功访问数据库: 📄 Meeting Logs\n",
            "\n",
            "=== 输入方式选择 ===\n",
            "1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\n",
            "2: 上传文本文件 (.txt/.docx)\n",
            "3: 直接粘贴文本\n",
            "\n",
            "请上传音频文件 (支持.mp3/.wav/.m4a/.opus):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f9983b7-8084-48b3-8e18-40c5e1e33952\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f9983b7-8084-48b3-8e18-40c5e1e33952\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1404911285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-1404911285.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mtranscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_transcript_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"转录文本长度\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-1404911285.py\u001b[0m in \u001b[0;36mhandle_transcript_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# === 添加的音频上传代码开始 ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n请上传音频文件 (支持.mp3/.wav/.m4a/.opus):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"上传音频\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"未上传任何文件\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装必要依赖（指定兼容版本）\n",
        "!pip uninstall -y whisper\n",
        "!pip install faster-whisper==0.10.0  # 锁定版本以避免API变更\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install tqdm python-docx notion-client langdetect langchain==0.1.13 langchain-openai==0.0.8 pydantic==2.5.2 httpx==0.27.0\n",
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "import subprocess\n",
        "import datetime\n",
        "import tempfile\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel, Field\n",
        "import httpx\n",
        "import concurrent.futures\n",
        "from functools import partial\n",
        "\n",
        "# 导入第三方库\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client, errors\n",
        "from langdetect import detect, LangDetectException\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# 清除代理环境变量（避免网络连接问题）\n",
        "for var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:\n",
        "    if var in os.environ:\n",
        "        del os.environ[var]\n",
        "\n",
        "# 初始化Notion客户端（修复httpx代理参数问题）\n",
        "http_client = httpx.Client()\n",
        "http_client.proxies = None  # 禁用代理\n",
        "\n",
        "notion = Client(\n",
        "    auth=userdata.get('NOTION_TOKEN'),\n",
        "    client=http_client\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 配置参数与初始化\n",
        "# ======================\n",
        "try:\n",
        "    # 从环境变量获取密钥\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_PAGE_ID = userdata.get('NOTION_PAGE_ID')\n",
        "\n",
        "    # 长音频处理参数\n",
        "    CHUNK_DURATION = 900  # 每块15分钟（秒）\n",
        "    OVERLAP_DURATION = 30  # 块间重叠30秒\n",
        "    MAX_CONCURRENT_CHUNKS = 1  # 单线程处理，避免文件竞争\n",
        "    # Notion块数量限制相关参数\n",
        "    MAX_TRANSCRIPT_SEGMENTS = 50  # 最多显示50条转录文本（避免块数量超限）\n",
        "\n",
        "    # 验证必要密钥\n",
        "    missing_creds = []\n",
        "    if not OPENAI_API_KEY:\n",
        "        missing_creds.append(\"OPENAI_API_KEY\")\n",
        "    if not NOTION_TOKEN:\n",
        "        missing_creds.append(\"NOTION_TOKEN\")\n",
        "    if not NOTION_PAGE_ID:\n",
        "        missing_creds.append(\"NOTION_PAGE_ID\")\n",
        "\n",
        "    if missing_creds:\n",
        "        raise ValueError(f\"缺少必要凭证: {', '.join(missing_creds)}\")\n",
        "\n",
        "    print(\"✅ 所有凭证已配置完成，准备处理会议内容\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 初始化失败: {str(e)}\")\n",
        "    print(\"\\n设置指南:\")\n",
        "    print(\"1. 点击左侧边栏的钥匙图标（Colab Secrets）\")\n",
        "    print(\"2. 添加以下密钥:\")\n",
        "    print(\"   - OPENAI_API_KEY: 你的OpenAI API密钥\")\n",
        "    print(\"   - NOTION_TOKEN: Notion集成令牌\")\n",
        "    print(\"   - NOTION_PAGE_ID: 用于存储报告的Notion页面ID\")\n",
        "    raise\n",
        "\n",
        "# ======================\n",
        "# 日志记录系统\n",
        "# ======================\n",
        "class MeetingLogger:\n",
        "    def __init__(self):\n",
        "        self.logs = {\n",
        "            \"start_time\": datetime.datetime.now().isoformat(),\n",
        "            \"steps\": [],\n",
        "            \"chunk_status\": {}\n",
        "        }\n",
        "\n",
        "    def log_step(self, step_name, status, details=None, error=None):\n",
        "        \"\"\"记录处理步骤\"\"\"\n",
        "        entry = {\n",
        "            \"step\": step_name,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"status\": status\n",
        "        }\n",
        "        if details:\n",
        "            entry[\"details\"] = details\n",
        "        if error:\n",
        "            entry[\"error\"] = str(error)\n",
        "        self.logs[\"steps\"].append(entry)\n",
        "\n",
        "    def log_chunk(self, chunk_id, status, error=None):\n",
        "        \"\"\"记录分块处理状态\"\"\"\n",
        "        self.logs[\"chunk_status\"][chunk_id] = {\n",
        "            \"status\": status,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"error\": str(error) if error else None\n",
        "        }\n",
        "\n",
        "    def get_completed_chunks(self):\n",
        "        \"\"\"获取成功的分块ID\"\"\"\n",
        "        return [k for k, v in self.logs[\"chunk_status\"].items() if v[\"status\"] == \"success\"]\n",
        "\n",
        "    def get_failed_chunks(self):\n",
        "        \"\"\"获取失败的分块ID\"\"\"\n",
        "        return [k for k, v in self.logs[\"chunk_status\"].items() if v[\"status\"] == \"failed\"]\n",
        "\n",
        "    def save_logs(self, filename=\"meeting_logs.json\"):\n",
        "        \"\"\"保存日志到文件\"\"\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(self.logs, f, indent=2)\n",
        "        return filename\n",
        "\n",
        "# 初始化日志系统\n",
        "logger = MeetingLogger()\n",
        "\n",
        "# ======================\n",
        "# 音频处理工具\n",
        "# ======================\n",
        "def get_audio_duration(audio_path):\n",
        "    \"\"\"获取音频时长（秒）\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"ffmpeg\", \"-i\", audio_path],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True\n",
        "        )\n",
        "        output = result.stdout\n",
        "\n",
        "        duration_match = re.search(r\"Duration: (\\d+:\\d+:\\d+\\.\\d+)\", output)\n",
        "        if not duration_match:\n",
        "            return 0.0\n",
        "\n",
        "        duration_str = duration_match.group(1)\n",
        "        h, m, s = duration_str.split(':')\n",
        "        return float(h) * 3600 + float(m) * 60 + float(s)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"获取音频时长\", \"warning\", error=str(e))\n",
        "        return 0.0\n",
        "\n",
        "def split_audio_into_chunks(audio_path):\n",
        "    \"\"\"将长音频分割为带重叠的块\"\"\"\n",
        "    logger.log_step(\"音频分块\", \"started\")\n",
        "\n",
        "    try:\n",
        "        total_duration = get_audio_duration(audio_path)\n",
        "        if total_duration <= 0:\n",
        "            raise ValueError(\"无法获取有效音频时长，可能文件损坏\")\n",
        "\n",
        "        # 计算分块数量\n",
        "        num_chunks = max(1, int((total_duration + CHUNK_DURATION - OVERLAP_DURATION) //\n",
        "                              (CHUNK_DURATION - OVERLAP_DURATION)))\n",
        "        logger.log_step(\"计算分块数量\", \"success\", {\"总时长(分钟)\": f\"{total_duration/60:.1f}\", \"分块数\": num_chunks})\n",
        "        print(f\"📊 音频将分割为 {num_chunks} 块（每块15分钟，重叠30秒）\")\n",
        "\n",
        "        # 创建临时目录存储分块\n",
        "        chunk_dir = tempfile.mkdtemp()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(num_chunks):\n",
        "            start_time = i * (CHUNK_DURATION - OVERLAP_DURATION)\n",
        "            end_time = min(start_time + CHUNK_DURATION, total_duration)\n",
        "\n",
        "            # 格式化为ffmpeg时间格式\n",
        "            start_str = str(datetime.timedelta(seconds=start_time))\n",
        "            duration_str = str(datetime.timedelta(seconds=end_time - start_time))\n",
        "\n",
        "            chunk_path = f\"{chunk_dir}/chunk_{i:03d}.wav\"\n",
        "\n",
        "            # 使用ffmpeg切割音频\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"ffmpeg\", \"-y\",  # 覆盖现有文件\n",
        "                    \"-i\", audio_path,\n",
        "                    \"-ss\", start_str,  # 起始时间\n",
        "                    \"-t\", duration_str,  # 持续时间\n",
        "                    \"-ar\", \"16000\",  # 统一采样率\n",
        "                    \"-ac\", \"1\",  # 单声道\n",
        "                    \"-acodec\", \"pcm_s16le\",  # 无损编码\n",
        "                    chunk_path\n",
        "                ],\n",
        "                check=True,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE\n",
        "            )\n",
        "\n",
        "            # 验证分块文件\n",
        "            if not os.path.exists(chunk_path) or os.path.getsize(chunk_path) < 1024:\n",
        "                raise RuntimeError(f\"分块 {i} 生成失败，文件大小异常\")\n",
        "\n",
        "            chunks.append({\n",
        "                \"id\": i,\n",
        "                \"path\": chunk_path,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": end_time,\n",
        "                \"dir\": chunk_dir  # 保留目录引用，避免提前删除\n",
        "            })\n",
        "\n",
        "        logger.log_step(\"音频分块\", \"success\")\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频分块\", \"failed\", error=str(e))\n",
        "        raise RuntimeError(f\"音频分块失败: {str(e)}\")\n",
        "\n",
        "# ======================\n",
        "# 语音转录（核心修复部分）\n",
        "# ======================\n",
        "# 全局模型变量（确保单例）\n",
        "global_model = None\n",
        "\n",
        "def transcribe_chunk(chunk):\n",
        "    \"\"\"转录单个音频块（修复Segment属性问题）\"\"\"\n",
        "    chunk_id = chunk[\"id\"]\n",
        "    chunk_path = chunk[\"path\"]\n",
        "    start_time = chunk[\"start_time\"]\n",
        "\n",
        "    try:\n",
        "        from faster_whisper import WhisperModel\n",
        "        global global_model\n",
        "\n",
        "        # 初始化模型（单例模式）\n",
        "        if global_model is None:\n",
        "            if not torch.cuda.is_available():\n",
        "                raise RuntimeError(\"请切换到GPU环境（Runtime > Change runtime type）\")\n",
        "\n",
        "            print(f\"🔧 加载 {chunk['model_size']} 模型（首次运行需下载约1.5GB）...\")\n",
        "            global_model = WhisperModel(\n",
        "                chunk[\"model_size\"],\n",
        "                device=\"cuda\",\n",
        "                compute_type=\"float16\",\n",
        "                download_root=\"/content/models\"\n",
        "            )\n",
        "            print(f\"✅ 模型加载成功\")\n",
        "\n",
        "        # 验证文件可访问\n",
        "        if not os.path.exists(chunk_path):\n",
        "            raise FileNotFoundError(f\"分块文件不存在: {chunk_path}\")\n",
        "\n",
        "        # 执行转录（不依赖confidence属性）\n",
        "        segments, info = global_model.transcribe(\n",
        "            chunk_path,\n",
        "            beam_size=2,\n",
        "            vad_filter=True,  # 启用语音活动检测\n",
        "            vad_parameters=dict(min_silence_duration_ms=300),\n",
        "            language=None  # 自动检测语言\n",
        "        )\n",
        "\n",
        "        # 处理转录结果（移除confidence属性）\n",
        "        timestamped_segments = []\n",
        "        for seg in segments:\n",
        "            timestamped_segments.append({\n",
        "                \"text\": seg.text.strip(),\n",
        "                \"start\": seg.start + start_time,  # 转换为全局时间\n",
        "                \"end\": seg.end + start_time\n",
        "                # 移除confidence属性，兼容新版本API\n",
        "            })\n",
        "\n",
        "        logger.log_chunk(chunk_id, \"success\")\n",
        "        return {\n",
        "            \"chunk_id\": chunk_id,\n",
        "            \"segments\": timestamped_segments,\n",
        "            \"language\": info.language\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_chunk(chunk_id, \"failed\", error=str(e))\n",
        "        print(f\"⚠️ 分块 {chunk_id} 转录失败: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def transcribe_long_audio(audio_path, model_size=\"small.en\"):\n",
        "    \"\"\"转录长音频（分块处理）\"\"\"\n",
        "    logger.log_step(\"音频转录\", \"started\", {\"模型\": model_size})\n",
        "\n",
        "    try:\n",
        "        global global_model\n",
        "        global_model = None  # 重置模型\n",
        "\n",
        "        # 分割音频为块\n",
        "        chunks = split_audio_into_chunks(audio_path)\n",
        "        num_chunks = len(chunks)\n",
        "\n",
        "        # 为每个分块添加模型参数\n",
        "        for chunk in chunks:\n",
        "            chunk[\"model_size\"] = model_size\n",
        "\n",
        "        # 转录所有分块（单线程避免文件竞争）\n",
        "        print(f\"🚀 开始转录 {num_chunks} 个分块...\")\n",
        "        results = []\n",
        "        for chunk in tqdm(chunks, desc=\"转录进度\"):\n",
        "            result = transcribe_chunk(chunk)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        # 重试失败的分块\n",
        "        failed_ids = logger.get_failed_chunks()\n",
        "        if failed_ids:\n",
        "            print(f\"🔄 重试 {len(failed_ids)} 个失败分块...\")\n",
        "            for chunk in chunks:\n",
        "                if chunk[\"id\"] in failed_ids:\n",
        "                    result = transcribe_chunk(chunk)\n",
        "                    if result:\n",
        "                        results.append(result)\n",
        "\n",
        "        # 按分块ID排序并合并结果\n",
        "        results.sort(key=lambda x: x[\"chunk_id\"])\n",
        "        all_segments = []\n",
        "        for res in results:\n",
        "            all_segments.extend(res[\"segments\"])\n",
        "\n",
        "        # 清理临时文件（最后清理，避免读取失败）\n",
        "        unique_dirs = list({chunk[\"dir\"] for chunk in chunks})\n",
        "        for dir_path in unique_dirs:\n",
        "            if os.path.exists(dir_path):\n",
        "                for f in os.listdir(dir_path):\n",
        "                    os.unlink(os.path.join(dir_path, f))\n",
        "                os.rmdir(dir_path)\n",
        "\n",
        "        # 检测语言\n",
        "        language = results[0][\"language\"] if results else \"en\"\n",
        "\n",
        "        # 验证转录结果\n",
        "        if not all_segments:\n",
        "            raise RuntimeError(\"未获取到有效转录内容，请检查音频质量\")\n",
        "\n",
        "        logger.log_step(\"音频转录\", \"success\", {\"总片段数\": len(all_segments)})\n",
        "        print(f\"✅ 转录完成（{len(all_segments)}个片段，检测语言: {language}）\")\n",
        "        return \" \".join([s[\"text\"] for s in all_segments]), all_segments, language\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频转录\", \"failed\", error=str(e))\n",
        "        raise RuntimeError(f\"转录过程失败: {str(e)}\")\n",
        "\n",
        "# ======================\n",
        "# 会议内容分析（修复dict属性错误）\n",
        "# ======================\n",
        "# 分析结果数据模型\n",
        "class ChunkAnalysis(BaseModel):\n",
        "    summary: str = Field(description=\"该片段的总结（100-200字）\")\n",
        "    key_points: list[str] = Field(description=\"该片段的关键点列表\")\n",
        "    action_items: list[dict] = Field(description=\"行动项列表，每个包含task、assignee、due_date\")\n",
        "    topics: list[str] = Field(description=\"讨论的话题列表\")\n",
        "\n",
        "class FullMeetingAnalysis(BaseModel):\n",
        "    meeting_title: str = Field(description=\"会议标题\")\n",
        "    participants: list[str] = Field(description=\"参与者名单\")\n",
        "    summary: str = Field(description=\"3-5段完整会议总结\")\n",
        "    key_points: dict = Field(description=\"按话题分组的全局关键点\")\n",
        "    action_items: list[dict] = Field(description=\"汇总的行动项\")\n",
        "    meeting_type: str = Field(description=\"会议类型\")\n",
        "    topics_flow: list[str] = Field(description=\"会议话题流转顺序\")\n",
        "\n",
        "def get_chunk_analysis_chain(language):\n",
        "    \"\"\"创建分块分析链（显式传递API密钥）\"\"\"\n",
        "    parser = JsonOutputParser(pydantic_object=ChunkAnalysis)\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"分析以下会议片段，提取关键信息（用{language}）：\\n{format_instructions}\\n会议片段：{transcript}\",\n",
        "        input_variables=[\"transcript\"],\n",
        "        partial_variables={\n",
        "            \"language\": \"中文\" if language.startswith('zh') else \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "    # 关键修复：显式传入API密钥\n",
        "    return prompt | ChatOpenAI(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0.3,\n",
        "        openai_api_key=OPENAI_API_KEY  # 直接使用全局变量中的密钥\n",
        "    ) | parser\n",
        "\n",
        "def get_full_analysis_chain(language):\n",
        "    \"\"\"创建全局分析链（显式传递API密钥）\"\"\"\n",
        "    parser = JsonOutputParser(pydantic_object=FullMeetingAnalysis)\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"基于以下各片段分析，生成完整会议报告（用{language}）：\\n{format_instructions}\\n片段分析：{chunk_analyses}\",\n",
        "        input_variables=[\"chunk_analyses\"],\n",
        "        partial_variables={\n",
        "            \"language\": \"中文\" if language.startswith('zh') else \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "    # 关键修复：显式传入API密钥\n",
        "    return prompt | ChatOpenAI(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0.3,\n",
        "        openai_api_key=OPENAI_API_KEY  # 直接使用全局变量中的密钥\n",
        "    ) | parser\n",
        "\n",
        "def analyze_meeting(transcript_segments, language='en'):\n",
        "    \"\"\"分析会议内容（分块分析+全局整合）\"\"\"\n",
        "    logger.log_step(\"会议分析\", \"started\")\n",
        "    print(\"\\n开始分析会议内容...\")\n",
        "\n",
        "    try:\n",
        "        # 按时间分割为分析块（45分钟/块）\n",
        "        ANALYSIS_CHUNK_DURATION = 2700\n",
        "        analysis_chunks = []\n",
        "        current_chunk = []\n",
        "\n",
        "        for seg in transcript_segments:\n",
        "            if not current_chunk:\n",
        "                current_chunk.append(seg)\n",
        "            else:\n",
        "                if seg[\"end\"] - current_chunk[0][\"start\"] <= ANALYSIS_CHUNK_DURATION:\n",
        "                    current_chunk.append(seg)\n",
        "                else:\n",
        "                    analysis_chunks.append(current_chunk)\n",
        "                    current_chunk = [seg]\n",
        "        if current_chunk:\n",
        "            analysis_chunks.append(current_chunk)\n",
        "\n",
        "        print(f\"📝 将会议内容分为 {len(analysis_chunks)} 个分析块\")\n",
        "\n",
        "        # 分块分析\n",
        "        chunk_analyses = []\n",
        "        chunk_chain = get_chunk_analysis_chain(language)\n",
        "\n",
        "        for i, chunk in enumerate(tqdm(analysis_chunks, desc=\"分析进度\")):\n",
        "            # 生成带时间戳的块文本\n",
        "            chunk_text = \"\\n\".join([\n",
        "                f\"[{str(datetime.timedelta(seconds=int(seg['start'])))}] {seg['text']}\"\n",
        "                for seg in chunk\n",
        "            ])\n",
        "\n",
        "            try:\n",
        "                analysis = chunk_chain.invoke({\"transcript\": chunk_text[:12000]})  # 限制长度\n",
        "                chunk_analyses.append({\n",
        "                    \"chunk_id\": i,\n",
        "                    \"start_time\": chunk[0][\"start\"],\n",
        "                    \"end_time\": chunk[-1][\"end\"],\n",
        "                    \"analysis\": analysis\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 分析块 {i} 失败: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if not chunk_analyses:\n",
        "            raise RuntimeError(\"所有分析块处理失败，无法生成报告\")\n",
        "\n",
        "        # 全局整合分析 - 修复：移除.dict()调用，因为分析结果已经是字典\n",
        "        full_chain = get_full_analysis_chain(language)\n",
        "        full_analysis = full_chain.invoke({\n",
        "            \"chunk_analyses\": json.dumps([\n",
        "                {\n",
        "                    \"时间段\": f\"{str(datetime.timedelta(seconds=int(c['start_time'])))} - {str(datetime.timedelta(seconds=int(c['end_time'])))}\",\n",
        "                    \"分析\": c[\"analysis\"]  # 关键修复：直接使用字典对象\n",
        "                } for c in chunk_analyses\n",
        "            ], ensure_ascii=False)\n",
        "        })\n",
        "\n",
        "        # 添加元数据 - 修复：如果full_analysis是Pydantic模型，先转字典\n",
        "        if hasattr(full_analysis, 'dict'):\n",
        "            full_analysis = full_analysis.dict()\n",
        "\n",
        "        full_analysis[\"language\"] = language\n",
        "        full_analysis[\"date\"] = datetime.datetime.now().isoformat()\n",
        "        full_analysis[\"total_duration\"] = f\"{(transcript_segments[-1]['end'] - transcript_segments[0]['start'])/3600:.2f}小时\"\n",
        "\n",
        "        logger.log_step(\"会议分析\", \"success\")\n",
        "        print(f\"✅ 会议分析完成（{len(full_analysis['topics_flow'])}个话题，{len(full_analysis['action_items'])}个行动项）\")\n",
        "        return full_analysis\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"会议分析失败: {str(e)}\"\n",
        "        logger.log_step(\"会议分析\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}\")\n",
        "        return {\"error\": error_msg}\n",
        "\n",
        "# ======================\n",
        "# Notion报告生成（修复块数量超限问题）\n",
        "# ======================\n",
        "def create_notion_report(meeting_data, transcript_segments):\n",
        "    \"\"\"在Notion中创建会议报告（控制块数量≤100）\"\"\"\n",
        "    logger.log_step(\"创建Notion报告\", \"started\")\n",
        "\n",
        "    try:\n",
        "        # 验证父页面是否存在\n",
        "        try:\n",
        "            parent_page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "            parent_title = parent_page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题页面')\n",
        "            print(f\"✅ 成功访问父页面: {parent_title}\")\n",
        "        except errors.APIResponseError as e:\n",
        "            raise RuntimeError(f\"Notion父页面访问失败: {str(e)}\")\n",
        "\n",
        "        # 创建新报告页面\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"page_id\": NOTION_PAGE_ID},\n",
        "            properties={\n",
        "                \"title\": {\n",
        "                    \"title\": [{\"text\": {\"content\": meeting_data.get(\"meeting_title\", \"会议报告\")[:200]}}]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "        page_id = new_page[\"id\"]\n",
        "\n",
        "        # 构建报告内容块（控制总数量≤100）\n",
        "        children_blocks = []\n",
        "\n",
        "        # 1. 会议概览（约2个块）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议概览\"}}]}\n",
        "        })\n",
        "        overview_text = f\"\"\"\n",
        "        标题: {meeting_data.get('meeting_title', '未命名会议')}\n",
        "        日期: {meeting_data.get('date', datetime.datetime.now().strftime('%Y-%m-%d'))}\n",
        "        总时长: {meeting_data.get('total_duration', '未知')}\n",
        "        参与者: {', '.join(meeting_data.get('participants', [])) or '未识别'}\n",
        "        语言: {meeting_data.get('language', '未知')}\n",
        "        \"\"\"\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": overview_text.strip()}}]}\n",
        "        })\n",
        "\n",
        "        # 2. 话题流转（话题数量+1个块）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"话题流转顺序\"}}]}\n",
        "        })\n",
        "        # 限制话题数量（避免块过多）\n",
        "        max_topics = 20  # 最多显示20个话题\n",
        "        for topic in meeting_data.get('topics_flow', [])[:max_topics]:\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"numbered_list_item\",\n",
        "                \"numbered_list_item\": {\"rich_text\": [{\"text\": {\"content\": topic}}]}\n",
        "            })\n",
        "\n",
        "        # 3. 会议总结（总结段落数+1个块）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议总结\"}}]}\n",
        "        })\n",
        "        # 限制总结段落数\n",
        "        max_summary_paras = 5  # 最多5段总结\n",
        "        for para in meeting_data.get('summary', '').split('\\n\\n')[:max_summary_paras]:\n",
        "            if para.strip():\n",
        "                children_blocks.append({\n",
        "                    \"object\": \"block\",\n",
        "                    \"type\": \"paragraph\",\n",
        "                    \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": para.strip()}}]}\n",
        "                })\n",
        "\n",
        "        # 4. 关键要点（话题数+要点数+1个块）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"关键要点\"}}]}\n",
        "        })\n",
        "        key_points = meeting_data.get('key_points', {})\n",
        "        max_key_topics = 10  # 最多10个关键话题\n",
        "        for topic, points in list(key_points.items())[:max_key_topics]:\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"heading_3\",\n",
        "                \"heading_3\": {\"rich_text\": [{\"text\": {\"content\": topic}}]}\n",
        "            })\n",
        "            # 限制每个话题的要点数量\n",
        "            max_points_per_topic = 5  # 每个话题最多5个要点\n",
        "            for point in points[:max_points_per_topic]:\n",
        "                children_blocks.append({\n",
        "                    \"object\": \"block\",\n",
        "                    \"type\": \"bulleted_list_item\",\n",
        "                    \"bulleted_list_item\": {\"rich_text\": [{\"text\": {\"content\": point}}]}\n",
        "                })\n",
        "\n",
        "        # 5. 行动项表格（行动项数+2个块）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"行动项\"}}]}\n",
        "        })\n",
        "        table_rows = []\n",
        "        max_actions = 20  # 最多显示20个行动项\n",
        "        for idx, item in enumerate(meeting_data.get('action_items', [])[:max_actions]):\n",
        "            table_rows.append([\n",
        "                [{\"text\": {\"content\": str(idx+1)}}],\n",
        "                [{\"text\": {\"content\": item.get('task', '')}}],\n",
        "                [{\"text\": {\"content\": item.get('assignee', '未分配')}}],\n",
        "                [{\"text\": {\"content\": item.get('due_date', '无')}}]\n",
        "            ])\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"table\",\n",
        "            \"table\": {\n",
        "                \"table_width\": 4,\n",
        "                \"has_column_header\": True,\n",
        "                \"children\": [\n",
        "                    {\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\n",
        "                            \"cells\": [\n",
        "                                [{\"text\": {\"content\": \"序号\"}}],\n",
        "                                [{\"text\": {\"content\": \"任务\"}}],\n",
        "                                [{\"text\": {\"content\": \"负责人\"}}],\n",
        "                                [{\"text\": {\"content\": \"截止日期\"}}]\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    *[{\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\"cells\": cells}\n",
        "                    } for cells in table_rows]\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 6. 转录文本（限制为MAX_TRANSCRIPT_SEGMENTS条，避免块超限）\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": f\"会议转录文本（节选，共{len(transcript_segments)}条）\"}}]}\n",
        "        })\n",
        "        # 只显示前MAX_TRANSCRIPT_SEGMENTS条转录文本\n",
        "        for seg in transcript_segments[:MAX_TRANSCRIPT_SEGMENTS]:\n",
        "            time_str = str(datetime.timedelta(seconds=int(seg[\"start\"])))\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"paragraph\",\n",
        "                \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": f\"[{time_str}] {seg['text']}\"}}]}\n",
        "            })\n",
        "\n",
        "        # 检查总块数，确保不超过100\n",
        "        if len(children_blocks) > 100:\n",
        "            # 紧急截断（保留核心内容）\n",
        "            children_blocks = children_blocks[:100]\n",
        "            print(f\"⚠️ 警告：内容块数量超限，已截断为100个块\")\n",
        "\n",
        "        # 将内容添加到页面\n",
        "        notion.blocks.children.append(block_id=page_id, children=children_blocks)\n",
        "        report_url = new_page.get(\"url\", \"\")\n",
        "\n",
        "        logger.log_step(\"创建Notion报告\", \"success\", {\"报告URL\": report_url, \"总块数\": len(children_blocks)})\n",
        "        print(f\"✅ Notion报告已生成（总块数: {len(children_blocks)}）\")\n",
        "        return report_url\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"创建Notion报告\", \"failed\", error=str(e))\n",
        "        print(f\"❌ 报告生成失败: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ======================\n",
        "# 输入处理\n",
        "# ======================\n",
        "def handle_input():\n",
        "    \"\"\"处理用户输入（音频或文本）\"\"\"\n",
        "    print(\"\\n=== 请选择输入方式 ===\")\n",
        "    print(\"1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\")\n",
        "    print(\"2: 上传带时间戳的转录文本 (.txt)\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"请选择 (1/2): \").strip() or \"1\"\n",
        "    except:\n",
        "        choice = \"1\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # 处理音频输入\n",
        "        print(\"\\n请上传音频文件（支持2-3小时会议录音）:\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"⚠️ 未检测到上传文件，请重试\")\n",
        "            return handle_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        audio_ext = os.path.splitext(filename)[1].lower()\n",
        "        supported_ext = ['.mp3', '.wav', '.m4a', '.opus']\n",
        "\n",
        "        if audio_ext not in supported_ext:\n",
        "            print(f\"❌ 不支持的文件格式（支持: {', '.join(supported_ext)}）\")\n",
        "            return handle_input()\n",
        "\n",
        "        # 保存音频文件\n",
        "        audio_path = f\"/tmp/{filename}\"\n",
        "        with open(audio_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "\n",
        "        # 检查音频时长\n",
        "        duration = get_audio_duration(audio_path)\n",
        "        if duration < 3600:  # 小于1小时\n",
        "            print(f\"⚠️ 检测到音频时长较短（{duration/60:.1f}分钟）\")\n",
        "            if input(\"是否继续使用长会议模式处理? (y/n): \").strip().lower() != 'y':\n",
        "                os.unlink(audio_path)\n",
        "                print(\"已切换到普通模式\")\n",
        "                return handle_input()\n",
        "\n",
        "        print(f\"🎵 音频信息: {filename}（{duration/60:.1f}分钟）\")\n",
        "\n",
        "        # 选择转录模型\n",
        "        print(\"\\n⚡ 请选择转录模型:\")\n",
        "        print(\"1: base.en - 快速模式（适合清晰语音）\")\n",
        "        print(\"2: small.en - 平衡模式（推荐，速度与精度兼顾）\")\n",
        "        print(\"3: medium.en - 高精度模式（适合复杂会议）\")\n",
        "\n",
        "        model_choice = input(\"请选择 (1-3，默认2): \").strip() or \"2\"\n",
        "        model_map = {\"1\": \"base.en\", \"2\": \"small.en\", \"3\": \"medium.en\"}\n",
        "        model_size = model_map.get(model_choice, \"small.en\")\n",
        "        print(f\"将使用 {model_size} 模型进行转录\")\n",
        "\n",
        "        # 执行转录\n",
        "        try:\n",
        "            transcript, segments, language = transcribe_long_audio(audio_path, model_size)\n",
        "            return transcript, segments, language\n",
        "        except Exception as e:\n",
        "            if os.path.exists(audio_path):\n",
        "                os.unlink(audio_path)\n",
        "            raise\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        # 处理文本输入\n",
        "        print(\"\\n请上传带时间戳的转录文本（格式示例: [00:05:10] 发言人: ...）:\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"⚠️ 未检测到上传文件，请重试\")\n",
        "            return handle_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        if not filename.endswith('.txt'):\n",
        "            print(\"❌ 仅支持.txt格式的文本文件\")\n",
        "            return handle_input()\n",
        "\n",
        "        # 解析文本\n",
        "        try:\n",
        "            transcript_text = uploaded[filename].decode('utf-8')\n",
        "            segments = []\n",
        "            time_pattern = re.compile(r'\\[(\\d+:\\d+:\\d+)\\]')  # 匹配[HH:MM:SS]\n",
        "\n",
        "            for line in transcript_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                match = time_pattern.search(line)\n",
        "                if match:\n",
        "                    time_str = match.group(1)\n",
        "                    text = time_pattern.sub('', line).strip()\n",
        "                    # 转换时间为秒\n",
        "                    h, m, s = map(int, time_str.split(':'))\n",
        "                    start_time = h * 3600 + m * 60 + s\n",
        "                    segments.append({\n",
        "                        \"text\": text,\n",
        "                        \"start\": start_time,\n",
        "                        \"end\": start_time + 30  # 估算结束时间\n",
        "                    })\n",
        "\n",
        "            if not segments:\n",
        "                raise ValueError(\"未检测到有效时间戳，请检查文本格式\")\n",
        "\n",
        "            # 检测语言\n",
        "            language = detect(transcript_text[:500]) if transcript_text else 'en'\n",
        "            print(f\"✅ 已解析转录文本（{len(segments)}个片段，检测语言: {language}）\")\n",
        "            return transcript_text, segments, language\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 文本解析失败: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ 无效选择，默认使用音频输入\")\n",
        "        return handle_input()\n",
        "\n",
        "# ======================\n",
        "# 主函数\n",
        "# ======================\n",
        "def main():\n",
        "    \"\"\"主函数：协调会议处理流程\"\"\"\n",
        "    print(\"=== 会议分析工具 ===\")\n",
        "    logger.log_step(\"会议处理流程\", \"started\")\n",
        "\n",
        "    try:\n",
        "        # 验证GPU环境\n",
        "        if not torch.cuda.is_available():\n",
        "            raise RuntimeError(\"请切换到GPU环境（Runtime > Change runtime type > 选择GPU）\")\n",
        "        print(f\"✅ 检测到GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "        # 处理输入\n",
        "        transcript, segments, language = handle_input()\n",
        "        if not transcript or not segments:\n",
        "            raise RuntimeError(\"未获取到有效会议内容\")\n",
        "\n",
        "        # 分析会议\n",
        "        meeting_data = analyze_meeting(segments, language)\n",
        "        if \"error\" in meeting_data:\n",
        "            raise RuntimeError(meeting_data[\"error\"])\n",
        "\n",
        "        # 生成Notion报告\n",
        "        report_url = create_notion_report(meeting_data, segments)\n",
        "        if not report_url:\n",
        "            raise RuntimeError(\"无法生成Notion报告\")\n",
        "\n",
        "        # 保存日志并输出结果\n",
        "        log_file = logger.save_logs()\n",
        "        print(f\"\\n🎉 会议处理完成！\")\n",
        "        print(f\"📄 会议报告: {report_url}\")\n",
        "        print(f\"📋 处理日志已保存到: {log_file}\")\n",
        "\n",
        "        # 显示报告链接\n",
        "        from IPython.display import HTML\n",
        "        display(HTML(f'<a href=\"{report_url}\" target=\"_blank\">点击查看Notion会议报告</a>'))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.save_logs(\"meeting_error_logs.json\")\n",
        "        print(f\"\\n❌ 处理失败: {str(e)}\")\n",
        "        print(\"错误详情已保存到 meeting_error_logs.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "NNnUaMEXajrA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5225dd308a5d4cb48bc302acb181a51a",
            "6d21b6d3ac7c4581aa961c2f137f69e5",
            "05510ae00af1484688597ea503caabbb",
            "80051aec09bc46bebf1d5ded88dd4c0b",
            "09c17810f3804b26b6081a02656a1b18",
            "843c05f5495247b381100505b7c705c6",
            "802582a9652746388242a5268447c6c0",
            "cdc8b29074ed48e1911f4e00a2a4d504",
            "108d76ae6f0849329b4d676c664bc9ce",
            "cbb1035b5d844018a8a3a4667667297e",
            "70c9bc2c823c41ed9a20587c08392164",
            "4d367cbf85394d18b92bb1eb2a084df4",
            "44b846a51b424fd596ffb878c653c4cf",
            "8751f7b6210f415abe0dc830d008cf7d",
            "47f335afd5fe494387deffc67087a5e4",
            "a61edf70480d441d8d2e942672c864eb",
            "9242974f1a45442c808fa0705f352966",
            "c27f195f3b3b464faade50443e552535",
            "534d82a48a1e461ab585882259d05c68",
            "2259349b9ea349788c3970bbe2c8ec83",
            "312bb335266d4ed69f8f7252305cd0fe",
            "56c3c6fc295849079148c1a12c6e8044",
            "798068dc88924125ab22f10886f23128",
            "500cab9c8d54477b8d36e2db22a54977",
            "91b0bed8d5fe4bed99769996f50e3cd1",
            "e8fb5ed8a63d4ed19b984a4d2ad5b89b",
            "a22957686d6e477fbe661dc8ec093028",
            "2d42717cecb9449796c0506f7424ffc3",
            "c049b95701a84e1a9ba5a8724e055c98",
            "1efb88bd6b7b42d88a065122dd707a20",
            "95bfe467e7464e8aae9fd99facc8e8a6",
            "5c9d245e038440079e80a6d5ddef382b",
            "dd2e117d0235474abf0627de4a9f6d02",
            "0b76a8e7784a4af982866b0f86002d18",
            "1aa693eef9df43309264df780dca2ac2",
            "959b21bc5db542ff9d898f88ee0c6693",
            "3b1bfa6c69604fbf84f326cb08464bed",
            "40fa370d582544f4b9127b03f9c488cd",
            "4cd96c6f61a54489b1e4457c3c6a6014",
            "5943bdf0509c472e8e5bb06f907eefb0",
            "1da30c836bdc460cab8d43cf1cd79f28",
            "90d3160710484c0dab01c261f5618cf9",
            "0c1bcff65e354aa9be14f2e0427da6e3",
            "6337cdf81d1e4ed68b4991add998577e"
          ]
        },
        "collapsed": true,
        "outputId": "e66734c1-3891-4af3-be77-4f92077acad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: faster-whisper==0.10.0 in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: av==11.* in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (11.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (0.15.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (1.22.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (1.1.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==0.10.0) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==0.10.0) (1.3.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-pbi2civ5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-pbi2civ5\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (1.26.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: notion-client in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: langchain==0.1.13 in /usr/local/lib/python3.11/dist-packages (0.1.13)\n",
            "Requirement already satisfied: langchain-openai==0.0.8 in /usr/local/lib/python3.11/dist-packages (0.0.8)\n",
            "Requirement already satisfied: pydantic==2.5.2 in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: httpx==0.27.0 in /usr/local/lib/python3.11/dist-packages (0.27.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.0.8) (1.96.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.0.8) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (4.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.0) (0.16.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.13) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain==0.1.13) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.13) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.13) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.13) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.13) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.13) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2024.11.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (1.1.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "✅ 所有凭证已配置完成，准备处理会议内容\n",
            "=== 会议分析工具 ===\n",
            "✅ 检测到GPU: Tesla T4\n",
            "\n",
            "=== 请选择输入方式 ===\n",
            "1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\n",
            "2: 上传带时间戳的转录文本 (.txt)\n",
            "请选择 (1/2): 1\n",
            "\n",
            "请上传音频文件（支持2-3小时会议录音）:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-10296944-e10b-4c47-a713-8f88e7da665b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-10296944-e10b-4c47-a713-8f88e7da665b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.mp3 to test.mp3\n",
            "⚠️ 检测到音频时长较短（52.6分钟）\n",
            "是否继续使用长会议模式处理? (y/n): y\n",
            "🎵 音频信息: test.mp3（52.6分钟）\n",
            "\n",
            "⚡ 请选择转录模型:\n",
            "1: base.en - 快速模式（适合清晰语音）\n",
            "2: small.en - 平衡模式（推荐，速度与精度兼顾）\n",
            "3: medium.en - 高精度模式（适合复杂会议）\n",
            "请选择 (1-3，默认2): 2\n",
            "将使用 small.en 模型进行转录\n",
            "📊 音频将分割为 4 块（每块15分钟，重叠30秒）\n",
            "🚀 开始转录 4 个分块...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r转录进度:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 加载 small.en 模型（首次运行需下载约1.5GB）...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5225dd308a5d4cb48bc302acb181a51a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d367cbf85394d18b92bb1eb2a084df4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "798068dc88924125ab22f10886f23128"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/484M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b76a8e7784a4af982866b0f86002d18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 模型加载成功\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "转录进度: 100%|██████████| 4/4 [01:54<00:00, 28.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 转录完成（847个片段，检测语言: en）\n",
            "\n",
            "开始分析会议内容...\n",
            "📝 将会议内容分为 2 个分析块\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "分析进度: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 会议分析完成（7个话题，0个行动项）\n",
            "✅ 成功访问父页面: Parent Page\n",
            "✅ Notion报告已生成（总块数: 74）\n",
            "\n",
            "🎉 会议处理完成！\n",
            "📄 会议报告: https://www.notion.so/Interview-with-Lauren-Graham-and-Game-Session-with-Maya-2355fee18e3781208495cbbb48558454\n",
            "📋 处理日志已保存到: meeting_logs.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"https://www.notion.so/Interview-with-Lauren-Graham-and-Game-Session-with-Maya-2355fee18e3781208495cbbb48558454\" target=\"_blank\">点击查看Notion会议报告</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装必要依赖（指定兼容版本）\n",
        "!pip uninstall -y whisper\n",
        "!pip install faster-whisper==0.10.0  # 锁定版本以避免API变更\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install tqdm python-docx notion-client langdetect langchain==0.1.13 langchain-openai==0.0.8 pydantic==2.5.2 httpx==0.27.0\n",
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "import subprocess\n",
        "import datetime\n",
        "import tempfile\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel, Field\n",
        "import httpx\n",
        "import concurrent.futures\n",
        "from functools import partial\n",
        "\n",
        "# 导入第三方库\n",
        "from google.colab import files, userdata\n",
        "from notion_client import Client, errors\n",
        "from langdetect import detect, LangDetectException\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# 清除代理环境变量（避免网络连接问题）\n",
        "for var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:\n",
        "    if var in os.environ:\n",
        "        del os.environ[var]\n",
        "\n",
        "# 初始化Notion客户端（修复httpx代理参数问题）\n",
        "http_client = httpx.Client()\n",
        "http_client.proxies = None  # 禁用代理\n",
        "\n",
        "notion = Client(\n",
        "    auth=userdata.get('NOTION_TOKEN'),\n",
        "    client=http_client\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 配置参数与初始化\n",
        "# ======================\n",
        "try:\n",
        "    # 从环境变量获取密钥\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    NOTION_TOKEN = userdata.get('NOTION_TOKEN')\n",
        "    NOTION_PAGE_ID = userdata.get('NOTION_PAGE_ID')\n",
        "    NOTION_DB_ID = userdata.get('NOTION_DB_ID')  # 数据库ID\n",
        "\n",
        "    # 长音频处理参数\n",
        "    CHUNK_DURATION = 900  # 每块15分钟（秒）\n",
        "    OVERLAP_DURATION = 30  # 块间重叠30秒\n",
        "    MAX_CONCURRENT_CHUNKS = 1  # 单线程处理，避免文件竞争\n",
        "    # Notion块数量限制相关参数\n",
        "    MAX_TRANSCRIPT_SEGMENTS = 50  # 最多显示50条转录文本\n",
        "    NOTION_RICH_TEXT_LIMIT = 1950  # Notion rich_text字段最大长度（留50字符余量）\n",
        "\n",
        "    # 验证必要密钥\n",
        "    missing_creds = []\n",
        "    if not OPENAI_API_KEY:\n",
        "        missing_creds.append(\"OPENAI_API_KEY\")\n",
        "    if not NOTION_TOKEN:\n",
        "        missing_creds.append(\"NOTION_TOKEN\")\n",
        "    if not NOTION_PAGE_ID:\n",
        "        missing_creds.append(\"NOTION_PAGE_ID\")\n",
        "    if not NOTION_DB_ID:\n",
        "        missing_creds.append(\"NOTION_DB_ID\")\n",
        "\n",
        "    if missing_creds:\n",
        "        raise ValueError(f\"缺少必要凭证: {', '.join(missing_creds)}\")\n",
        "\n",
        "    print(\"✅ 所有凭证已配置完成，准备处理会议内容\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 初始化失败: {str(e)}\")\n",
        "    print(\"\\n设置指南:\")\n",
        "    print(\"1. 点击左侧边栏的钥匙图标（Colab Secrets）\")\n",
        "    print(\"2. 添加以下密钥:\")\n",
        "    print(\"   - OPENAI_API_KEY: 你的OpenAI API密钥\")\n",
        "    print(\"   - NOTION_TOKEN: Notion集成令牌\")\n",
        "    print(\"   - NOTION_PAGE_ID: 会议集成页ID\")\n",
        "    print(\"   - NOTION_DB_ID: 目标数据库ID\")\n",
        "    raise\n",
        "\n",
        "# ======================\n",
        "# 日志记录系统\n",
        "# ======================\n",
        "class MeetingLogger:\n",
        "    def __init__(self):\n",
        "        self.logs = {\n",
        "            \"start_time\": datetime.datetime.now().isoformat(),\n",
        "            \"steps\": [],\n",
        "            \"chunk_status\": {}\n",
        "        }\n",
        "\n",
        "    def log_step(self, step_name, status, details=None, error=None):\n",
        "        entry = {\n",
        "            \"step\": step_name,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"status\": status\n",
        "        }\n",
        "        if details:\n",
        "            entry[\"details\"] = details\n",
        "        if error:\n",
        "            entry[\"error\"] = str(error)\n",
        "        self.logs[\"steps\"].append(entry)\n",
        "\n",
        "    def log_chunk(self, chunk_id, status, error=None):\n",
        "        self.logs[\"chunk_status\"][chunk_id] = {\n",
        "            \"status\": status,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"error\": str(error) if error else None\n",
        "        }\n",
        "\n",
        "    def get_completed_chunks(self):\n",
        "        return [k for k, v in self.logs[\"chunk_status\"].items() if v[\"status\"] == \"success\"]\n",
        "\n",
        "    def get_failed_chunks(self):\n",
        "        return [k for k, v in self.logs[\"chunk_status\"].items() if v[\"status\"] == \"failed\"]\n",
        "\n",
        "    def save_logs(self, filename=\"meeting_logs.json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(self.logs, f, indent=2)\n",
        "        return filename\n",
        "\n",
        "logger = MeetingLogger()\n",
        "\n",
        "# ======================\n",
        "# 音频处理工具\n",
        "# ======================\n",
        "def get_audio_duration(audio_path):\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"ffmpeg\", \"-i\", audio_path],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True\n",
        "        )\n",
        "        output = result.stdout\n",
        "\n",
        "        duration_match = re.search(r\"Duration: (\\d+:\\d+:\\d+\\.\\d+)\", output)\n",
        "        if not duration_match:\n",
        "            return 0.0\n",
        "\n",
        "        duration_str = duration_match.group(1)\n",
        "        h, m, s = duration_str.split(':')\n",
        "        return float(h) * 3600 + float(m) * 60 + float(s)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"获取音频时长\", \"warning\", error=str(e))\n",
        "        return 0.0\n",
        "\n",
        "def split_audio_into_chunks(audio_path):\n",
        "    logger.log_step(\"音频分块\", \"started\")\n",
        "\n",
        "    try:\n",
        "        total_duration = get_audio_duration(audio_path)\n",
        "        if total_duration <= 0:\n",
        "            raise ValueError(\"无法获取有效音频时长，可能文件损坏\")\n",
        "\n",
        "        num_chunks = max(1, int((total_duration + CHUNK_DURATION - OVERLAP_DURATION) //\n",
        "                              (CHUNK_DURATION - OVERLAP_DURATION)))\n",
        "        logger.log_step(\"计算分块数量\", \"success\", {\"总时长(分钟)\": f\"{total_duration/60:.1f}\", \"分块数\": num_chunks})\n",
        "        print(f\"📊 音频将分割为 {num_chunks} 块（每块15分钟，重叠30秒）\")\n",
        "\n",
        "        chunk_dir = tempfile.mkdtemp()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(num_chunks):\n",
        "            start_time = i * (CHUNK_DURATION - OVERLAP_DURATION)\n",
        "            end_time = min(start_time + CHUNK_DURATION, total_duration)\n",
        "\n",
        "            start_str = str(datetime.timedelta(seconds=start_time))\n",
        "            duration_str = str(datetime.timedelta(seconds=end_time - start_time))\n",
        "\n",
        "            chunk_path = f\"{chunk_dir}/chunk_{i:03d}.wav\"\n",
        "\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"ffmpeg\", \"-y\",\n",
        "                    \"-i\", audio_path,\n",
        "                    \"-ss\", start_str,\n",
        "                    \"-t\", duration_str,\n",
        "                    \"-ar\", \"16000\",\n",
        "                    \"-ac\", \"1\",\n",
        "                    \"-acodec\", \"pcm_s16le\",\n",
        "                    chunk_path\n",
        "                ],\n",
        "                check=True,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE\n",
        "            )\n",
        "\n",
        "            if not os.path.exists(chunk_path) or os.path.getsize(chunk_path) < 1024:\n",
        "                raise RuntimeError(f\"分块 {i} 生成失败，文件大小异常\")\n",
        "\n",
        "            chunks.append({\n",
        "                \"id\": i,\n",
        "                \"path\": chunk_path,\n",
        "                \"start_time\": start_time,\n",
        "                \"end_time\": end_time,\n",
        "                \"dir\": chunk_dir\n",
        "            })\n",
        "\n",
        "        logger.log_step(\"音频分块\", \"success\")\n",
        "        return chunks\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频分块\", \"failed\", error=str(e))\n",
        "        raise RuntimeError(f\"音频分块失败: {str(e)}\")\n",
        "\n",
        "# ======================\n",
        "# 语音转录\n",
        "# ======================\n",
        "global_model = None\n",
        "\n",
        "def transcribe_chunk(chunk):\n",
        "    chunk_id = chunk[\"id\"]\n",
        "    chunk_path = chunk[\"path\"]\n",
        "    start_time = chunk[\"start_time\"]\n",
        "\n",
        "    try:\n",
        "        from faster_whisper import WhisperModel\n",
        "        global global_model\n",
        "\n",
        "        if global_model is None:\n",
        "            if not torch.cuda.is_available():\n",
        "                raise RuntimeError(\"请切换到GPU环境（Runtime > Change runtime type）\")\n",
        "\n",
        "            print(f\"🔧 加载 {chunk['model_size']} 模型（首次运行需下载约1.5GB）...\")\n",
        "            global_model = WhisperModel(\n",
        "                chunk[\"model_size\"],\n",
        "                device=\"cuda\",\n",
        "                compute_type=\"float16\",\n",
        "                download_root=\"/content/models\"\n",
        "            )\n",
        "            print(f\"✅ 模型加载成功\")\n",
        "\n",
        "        if not os.path.exists(chunk_path):\n",
        "            raise FileNotFoundError(f\"分块文件不存在: {chunk_path}\")\n",
        "\n",
        "        segments, info = global_model.transcribe(\n",
        "            chunk_path,\n",
        "            beam_size=2,\n",
        "            vad_filter=True,\n",
        "            vad_parameters=dict(min_silence_duration_ms=300),\n",
        "            language=None  # 自动检测语言\n",
        "        )\n",
        "\n",
        "        timestamped_segments = []\n",
        "        for seg in segments:\n",
        "            timestamped_segments.append({\n",
        "                \"text\": seg.text.strip(),\n",
        "                \"start\": seg.start + start_time,\n",
        "                \"end\": seg.end + start_time,\n",
        "                \"language\": info.language  # 记录当前块的语言\n",
        "            })\n",
        "\n",
        "        logger.log_chunk(chunk_id, \"success\")\n",
        "        return {\n",
        "            \"chunk_id\": chunk_id,\n",
        "            \"segments\": timestamped_segments,\n",
        "            \"language\": info.language\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_chunk(chunk_id, \"failed\", error=str(e))\n",
        "        print(f\"⚠️ 分块 {chunk_id} 转录失败: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def transcribe_long_audio(audio_path, model_size=\"small.en\"):\n",
        "    logger.log_step(\"音频转录\", \"started\", {\"模型\": model_size})\n",
        "\n",
        "    try:\n",
        "        global global_model\n",
        "        global_model = None\n",
        "\n",
        "        chunks = split_audio_into_chunks(audio_path)\n",
        "        num_chunks = len(chunks)\n",
        "\n",
        "        for chunk in chunks:\n",
        "            chunk[\"model_size\"] = model_size\n",
        "\n",
        "        print(f\"🚀 开始转录 {num_chunks} 个分块...\")\n",
        "        results = []\n",
        "        for chunk in tqdm(chunks, desc=\"转录进度\"):\n",
        "            result = transcribe_chunk(chunk)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        failed_ids = logger.get_failed_chunks()\n",
        "        if failed_ids:\n",
        "            print(f\"🔄 重试 {len(failed_ids)} 个失败分块...\")\n",
        "            for chunk in chunks:\n",
        "                if chunk[\"id\"] in failed_ids:\n",
        "                    result = transcribe_chunk(chunk)\n",
        "                    if result:\n",
        "                        results.append(result)\n",
        "\n",
        "        results.sort(key=lambda x: x[\"chunk_id\"])\n",
        "        all_segments = []\n",
        "        for res in results:\n",
        "            all_segments.extend(res[\"segments\"])\n",
        "\n",
        "        unique_dirs = list({chunk[\"dir\"] for chunk in chunks})\n",
        "        for dir_path in unique_dirs:\n",
        "            if os.path.exists(dir_path):\n",
        "                for f in os.listdir(dir_path):\n",
        "                    os.unlink(os.path.join(dir_path, f))\n",
        "                os.rmdir(dir_path)\n",
        "\n",
        "        # 提取所有出现的语言（去重）\n",
        "        all_languages = list({seg.get(\"language\", \"unknown\") for seg in all_segments})\n",
        "        primary_language = results[0][\"language\"] if results else \"en\"\n",
        "\n",
        "        # 计算会议总时长（秒）\n",
        "        total_seconds = all_segments[-1][\"end\"] - all_segments[0][\"start\"] if all_segments else 0\n",
        "\n",
        "        logger.log_step(\"音频转录\", \"success\", {\"总片段数\": len(all_segments), \"所有语言\": all_languages})\n",
        "        print(f\"✅ 转录完成（{len(all_segments)}个片段，主要语言: {primary_language}，所有语言: {all_languages}）\")\n",
        "        return \" \".join([s[\"text\"] for s in all_segments]), all_segments, primary_language, all_languages, total_seconds\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"音频转录\", \"failed\", error=str(e))\n",
        "        raise RuntimeError(f\"转录过程失败: {str(e)}\")\n",
        "\n",
        "# ======================\n",
        "# 会议内容分析\n",
        "# ======================\n",
        "class ChunkAnalysis(BaseModel):\n",
        "    summary: str = Field(description=\"该片段的总结（100-200字）\")\n",
        "    key_points: list[str] = Field(description=\"该片段的关键点键列表（客观事实）\")\n",
        "    action_items: list[dict] = Field(description=\"行动项列表，每个包含task、assignee、due_date\")\n",
        "    topics: list[str] = Field(description=\"讨论的话题列表\")\n",
        "    decisions: list[str] = Field(description=\"该片段中达成的具体决定（明确的结论）\")\n",
        "    concerns: list[str] = Field(description=\"该片段中提出的担忧、问题或风险\")\n",
        "    platform: str = Field(description=\"会议发生的平台或场所（如Zoom、会议室A等）\")  # 新增字段\n",
        "\n",
        "class FullMeetingAnalysis(BaseModel):\n",
        "    meeting_title: str = Field(description=\"会议标题\")\n",
        "    participants: list[str] = Field(description=\"参与者名单\")\n",
        "    summary: str = Field(description=\"3-5段完整会议总结\")\n",
        "    key_points: dict = Field(description=\"按话题分组组的全局关键点（客观事实）\")\n",
        "    action_items: list[dict] = Field(description=\"汇总的行动项\")\n",
        "    meeting_type: str = Field(description=\"会议类型（如周会、项目评审会、头脑风暴等）\")\n",
        "    topics_flow: list[str] = Field(description=\"会议话题流转顺序\")\n",
        "    decisions: list[str] = Field(description=\"会议中达成的所有决定（明确结论，如“同意项目延期”）\")\n",
        "    concerns: list[str] = Field(description=\"会议中提出的所有担忧、问题或风险（如“资源不足”）\")\n",
        "    platform: str = Field(description=\"会议发生的平台或场所（如Zoom、Teams、会议室B等）\")  # 新增字段\n",
        "\n",
        "def get_chunk_analysis_chain(language):\n",
        "    parser = JsonOutputParser(pydantic_object=ChunkAnalysis)\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"分析以下会议片段，提取关键信息（用{language}）：\n",
        "{format_instructions}\n",
        "注意：\n",
        "- key_points：客观事实（如“项目进度落后20%”）\n",
        "- decisions：明确达成的结论（如“决定增加2名开发人员”）\n",
        "- concerns：提出的担忧（如“预算可能超支”）\n",
        "- platform：会议进行的平台或物理场所（如Zoom、公司3楼会议室等）\n",
        "会议片段：{transcript}\"\"\",\n",
        "        input_variables=[\"transcript\"],\n",
        "        partial_variables={\n",
        "            \"language\": \"中文\" if language.startswith('zh') else \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "    return prompt | ChatOpenAI(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0.3,\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    ) | parser\n",
        "\n",
        "def get_full_analysis_chain(language):\n",
        "    parser = JsonOutputParser(pydantic_object=FullMeetingAnalysis)\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"基于以下各片段分析，生成完整会议报告（用{language}）：\n",
        "{format_instructions}\n",
        "注意：\n",
        "- key_points：仅包含客观事实，不包含结论\n",
        "- decisions：必须是明确达成的结论（有具体结果）\n",
        "- concerns：必须是提出的问题或风险（未解决的担忧）\n",
        "- platform：明确会议发生的平台或场所（如Zoom、Teams、总部会议室等）\n",
        "- meeting_type：明确会议类型（如周例会、项目启动会、评审会等）\n",
        "片段分析：{chunk_analyses}\"\"\",\n",
        "        input_variables=[\"chunk_analyses\"],\n",
        "        partial_variables={\n",
        "            \"language\": \"中文\" if language.startswith('zh') else \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        }\n",
        "    )\n",
        "    return prompt | ChatOpenAI(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0.3,\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    ) | parser\n",
        "\n",
        "def analyze_meeting(transcript_segments, language='en'):\n",
        "    logger.log_step(\"会议分析\", \"started\")\n",
        "    print(\"\\n开始分析会议内容...\")\n",
        "\n",
        "    try:\n",
        "        ANALYSIS_CHUNK_DURATION = 2700\n",
        "        analysis_chunks = []\n",
        "        current_chunk = []\n",
        "\n",
        "        for seg in transcript_segments:\n",
        "            if not current_chunk:\n",
        "                current_chunk.append(seg)\n",
        "            else:\n",
        "                if seg[\"end\"] - current_chunk[0][\"start\"] <= ANALYSIS_CHUNK_DURATION:\n",
        "                    current_chunk.append(seg)\n",
        "                else:\n",
        "                    analysis_chunks.append(current_chunk)\n",
        "                    current_chunk = [seg]\n",
        "        if current_chunk:\n",
        "            analysis_chunks.append(current_chunk)\n",
        "\n",
        "        print(f\"📝 将会议内容分为 {len(analysis_chunks)} 个分析块\")\n",
        "\n",
        "        chunk_analyses = []\n",
        "        chunk_chain = get_chunk_analysis_chain(language)\n",
        "\n",
        "        for i, chunk in enumerate(tqdm(analysis_chunks, desc=\"分析进度\")):\n",
        "            chunk_text = \"\\n\".join([\n",
        "                f\"[{str(datetime.timedelta(seconds=int(seg['start'])))}] {seg['text']}\"\n",
        "                for seg in chunk\n",
        "            ])\n",
        "\n",
        "            try:\n",
        "                analysis = chunk_chain.invoke({\"transcript\": chunk_text[:12000]})\n",
        "                chunk_analyses.append({\n",
        "                    \"chunk_id\": i,\n",
        "                    \"start_time\": chunk[0][\"start\"],\n",
        "                    \"end_time\": chunk[-1][\"end\"],\n",
        "                    \"analysis\": analysis\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 分析块 {i} 失败: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if not chunk_analyses:\n",
        "            raise RuntimeError(\"所有分析块处理失败，无法生成报告\")\n",
        "\n",
        "        full_chain = get_full_analysis_chain(language)\n",
        "        full_analysis = full_chain.invoke({\n",
        "            \"chunk_analyses\": json.dumps([\n",
        "                {\n",
        "                    \"时间段\": f\"{str(datetime.timedelta(seconds=int(c['start_time'])))} - {str(datetime.timedelta(seconds=int(c['end_time'])))}\",\n",
        "                    \"分析\": c[\"analysis\"]\n",
        "                } for c in chunk_analyses\n",
        "            ], ensure_ascii=False)\n",
        "        })\n",
        "\n",
        "        if hasattr(full_analysis, 'dict'):\n",
        "            full_analysis = full_analysis.dict()\n",
        "\n",
        "        full_analysis[\"language\"] = language\n",
        "        full_analysis[\"date\"] = datetime.datetime.now().isoformat()\n",
        "\n",
        "        logger.log_step(\"会议分析\", \"success\")\n",
        "        print(f\"✅ 会议分析完成（{len(full_analysis.get('topics_flow', []))}个话题，{len(full_analysis.get('action_items', []))}个行动项）\")\n",
        "        return full_analysis\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"会议分析失败: {str(e)}\"\n",
        "        logger.log_step(\"会议分析\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}\")\n",
        "        return {\"error\": error_msg}\n",
        "\n",
        "# ======================\n",
        "# Notion操作\n",
        "# ======================\n",
        "def create_notion_report(meeting_data, transcript_segments):\n",
        "    logger.log_step(\"创建Notion报告\", \"started\")\n",
        "\n",
        "    try:\n",
        "        try:\n",
        "            parent_page = notion.pages.retrieve(NOTION_PAGE_ID)\n",
        "            parent_title = parent_page.get('properties', {}).get('title', {}).get('title', [{}])[0].get('plain_text', '无标题页面')\n",
        "            print(f\"✅ 成功访问父页面: {parent_title}\")\n",
        "        except errors.APIResponseError as e:\n",
        "            raise RuntimeError(f\"Notion父页面访问失败: {str(e)}\")\n",
        "\n",
        "        new_page = notion.pages.create(\n",
        "            parent={\"page_id\": NOTION_PAGE_ID},\n",
        "            properties={\n",
        "                \"title\": {\n",
        "                    \"title\": [{\"text\": {\"content\": meeting_data.get(\"meeting_title\", \"会议报告\")[:200]}}]\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "        page_id = new_page[\"id\"]\n",
        "\n",
        "        # 构建报告内容块\n",
        "        children_blocks = []\n",
        "\n",
        "        # 1. 会议概览\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议概览\"}}]}\n",
        "        })\n",
        "        overview_text = f\"\"\"\n",
        "        **标题**: {meeting_data.get('meeting_title', '未命名会议')}\n",
        "        **日期**: {meeting_data.get('date', datetime.datetime.now().strftime('%Y年%m月%d日'))}\n",
        "        **参与者**: {', '.join(meeting_data.get('participants', [])) or '未识别'}\n",
        "        **类型**: {meeting_data.get('meeting_type', '未指定')}\n",
        "        **平台**: {meeting_data.get('platform', '未指定')}\n",
        "        **语言**: {', '.join(meeting_data.get('all_languages', [])) or '未知'}\n",
        "        \"\"\"\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"paragraph\",\n",
        "            \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": overview_text.strip()}}]}\n",
        "        })\n",
        "\n",
        "        # 2. 话题流转\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"话题流转顺序\"}}]}\n",
        "        })\n",
        "        max_topics = 20\n",
        "        for topic in meeting_data.get('topics_flow', [])[:max_topics]:\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"numbered_list_item\",\n",
        "                \"numbered_list_item\": {\"rich_text\": [{\"text\": {\"content\": topic}}]}\n",
        "            })\n",
        "\n",
        "        # 3. 会议总结\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"会议总结\"}}]}\n",
        "        })\n",
        "        max_summary_paras = 5\n",
        "        for para in meeting_data.get('summary', '').split('\\n\\n')[:max_summary_paras]:\n",
        "            if para.strip():\n",
        "                children_blocks.append({\n",
        "                    \"object\": \"block\",\n",
        "                    \"type\": \"paragraph\",\n",
        "                    \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": para.strip()}}]}\n",
        "                })\n",
        "\n",
        "        # 4. 关键要点\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"关键要点\"}}]}\n",
        "        })\n",
        "        key_points = meeting_data.get('key_points', {})\n",
        "        max_key_topics = 10\n",
        "        for topic, points in list(key_points.items())[:max_key_topics]:\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"heading_3\",\n",
        "                \"heading_3\": {\"rich_text\": [{\"text\": {\"content\": topic}}]}\n",
        "            })\n",
        "            max_points_per_topic = 5\n",
        "            for point in points[:max_points_per_topic]:\n",
        "                children_blocks.append({\n",
        "                    \"object\": \"block\",\n",
        "                    \"type\": \"bulleted_list_item\",\n",
        "                    \"bulleted_list_item\": {\"rich_text\": [{\"text\": {\"content\": point}}]}\n",
        "                })\n",
        "\n",
        "        # 5. 行动项表格\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": \"行动项\"}}]}\n",
        "        })\n",
        "        table_rows = []\n",
        "        max_actions = 20\n",
        "        for idx, item in enumerate(meeting_data.get('action_items', [])[:max_actions]):\n",
        "            table_rows.append([\n",
        "                [{\"text\": {\"content\": str(idx+1)}}],\n",
        "                [{\"text\": {\"content\": item.get('task', '')}}],\n",
        "                [{\"text\": {\"content\": item.get('assignee', '未分配')}}],\n",
        "                [{\"text\": {\"content\": item.get('due_date', '无')}}]\n",
        "            ])\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"table\",\n",
        "            \"table\": {\n",
        "                \"table_width\": 4,\n",
        "                \"has_column_header\": True,\n",
        "                \"children\": [\n",
        "                    {\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\n",
        "                            \"cells\": [\n",
        "                                [{\"text\": {\"content\": \"序号\"}}],\n",
        "                                [{\"text\": {\"content\": \"任务\"}}],\n",
        "                                [{\"text\": {\"content\": \"负责人\"}}],\n",
        "                                [{\"text\": {\"content\": \"截止日期\"}}]\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    *[{\n",
        "                        \"object\": \"block\",\n",
        "                        \"type\": \"table_row\",\n",
        "                        \"table_row\": {\"cells\": cells}\n",
        "                    } for cells in table_rows]\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # 6. 转录文本\n",
        "        children_blocks.append({\n",
        "            \"object\": \"block\",\n",
        "            \"type\": \"heading_2\",\n",
        "            \"heading_2\": {\"rich_text\": [{\"text\": {\"content\": f\"会议转录文本（节选，共{len(transcript_segments)}条）\"}}]}\n",
        "        })\n",
        "        for seg in transcript_segments[:MAX_TRANSCRIPT_SEGMENTS]:\n",
        "            time_str = str(datetime.timedelta(seconds=int(seg[\"start\"])))\n",
        "            children_blocks.append({\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"paragraph\",\n",
        "                \"paragraph\": {\"rich_text\": [{\"text\": {\"content\": f\"[{time_str}] {seg['text']}\"}}]}\n",
        "            })\n",
        "\n",
        "        # 检查总块数\n",
        "        if len(children_blocks) > 100:\n",
        "            children_blocks = children_blocks[:100]\n",
        "            print(f\"⚠️ 警告：内容块数量超限，已截断为100个块\")\n",
        "\n",
        "        notion.blocks.children.append(block_id=page_id, children=children_blocks)\n",
        "        report_url = new_page.get(\"url\", \"\")\n",
        "\n",
        "        logger.log_step(\"创建Notion报告\", \"success\", {\"报告URL\": report_url, \"总块数\": len(children_blocks)})\n",
        "        print(f\"✅ Notion报告已生成（总块数: {len(children_blocks)}）\")\n",
        "        return report_url\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log_step(\"创建Notion报告\", \"failed\", error=str(e))\n",
        "        print(f\"❌ 报告生成失败: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# 写入Notion数据库（核心修改：匹配新表头）\n",
        "def write_to_notion_database(meeting_data, full_transcript, all_languages, total_seconds):\n",
        "    logger.log_step(\"写入Notion数据库\", \"started\")\n",
        "\n",
        "    try:\n",
        "        # 辅助函数：截断文本到Notion允许的最大长度\n",
        "        def truncate_text(text, max_length):\n",
        "            if text and len(text) > max_length:\n",
        "                return text[:max_length-3] + \"...\"  # 预留3个字符给省略号\n",
        "            return text or \"\"\n",
        "\n",
        "        # 辅助函数：转换秒数为\"x小时x分钟\"格式（不足1分钟按1分钟算）\n",
        "        def format_duration(seconds):\n",
        "            hours = seconds // 3600\n",
        "            remaining_seconds = seconds % 3600\n",
        "            minutes = (remaining_seconds + 59) // 60  # 向上取整\n",
        "            return f\"{hours}小时{minutes}分钟\"\n",
        "\n",
        "        # 辅助函数：转换秒数为总分钟数（用于数字类型的Duration字段）\n",
        "        def get_total_minutes(seconds):\n",
        "            return (seconds + 59) // 60  # 向上取整\n",
        "\n",
        "        # 1. 准备数据库字段内容（严格匹配表头）\n",
        "        database_properties = {\n",
        "            # 会议标题（文本类型）\n",
        "            \"Meeting Title\": {\"title\": [{\"text\": {\"content\": meeting_data.get(\"meeting_title\", \"Untitled\")}}]},\n",
        "            # 参与者（文本类型）\n",
        "            \"Participant\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \", \".join(meeting_data.get(\"participant\", [])),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 日期（日期类型，格式xxxx年xx月xx日）\n",
        "            \"Date\": {\n",
        "                \"date\": {\n",
        "                    \"start\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),  # Notion日期格式需为ISO\n",
        "                    \"end\": None\n",
        "                }\n",
        "            },\n",
        "            # 时长（数字类型，存储总分钟数）\n",
        "            \"Duration\": {\n",
        "                \"number\": get_total_minutes(total_seconds)\n",
        "            },\n",
        "            # 会议类型（文本类型）\n",
        "            \"Meeting Type\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    meeting_data.get(\"meeting_type\", \"未指定\"),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议平台（选择类型，确保值在预设选项中）\n",
        "            \"Platform\": {\"select\": {\"name\": meeting_data.get(\"platform\", \"Unknown\")}},\n",
        "            # 会议完整原文（文本类型）\n",
        "            \"original meeting script\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    full_transcript,\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议语言（文本类型）\n",
        "            \"language\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \", \".join(all_languages),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议总结（文本类型）\n",
        "            \"Summary\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    meeting_data.get(\"summary\", \"\"),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议决定（文本类型）\n",
        "            \"Decisions\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \"\\n\".join([f\"- {d}\" for d in meeting_data.get(\"decisions\", [])]),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议担忧（文本类型）\n",
        "            \"Concerns\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \"\\n\".join([f\"- {c}\" for c in meeting_data.get(\"concerns\", [])]),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 会议要点（文本类型）\n",
        "            \"Key Points\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \"\\n\".join([f\"- {topic}: {', '.join(points)}\"\n",
        "                              for topic, points in meeting_data.get(\"key_points\", {}).items()]),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            },\n",
        "            # 行动项（文本类型）\n",
        "            \"Action Items\": {\n",
        "                \"rich_text\": [{\"text\": {\"content\": truncate_text(\n",
        "                    \"\\n\".join([f\"- {item.get('task', '')}（负责人：{item.get('assignee', '未分配')}）\"\n",
        "                              for item in meeting_data.get(\"action_items\", [])]),\n",
        "                    NOTION_RICH_TEXT_LIMIT\n",
        "                )}}]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 2. 写入数据库\n",
        "        new_db_page = notion.pages.create(\n",
        "            parent={\"database_id\": NOTION_DB_ID},\n",
        "            properties=database_properties\n",
        "        )\n",
        "\n",
        "        logger.log_step(\"写入Notion数据库\", \"success\", {\"数据库页面ID\": new_db_page[\"id\"]})\n",
        "        print(f\"✅ 成功写入Notion数据库（条目ID: {new_db_page['id']}）\")\n",
        "        print(f\"⏱️ 会议时长: {format_duration(total_seconds)}\")\n",
        "        return new_db_page[\"id\"]\n",
        "\n",
        "    except errors.APIResponseError as e:\n",
        "        error_msg = f\"数据库写入失败: {str(e)}\"\n",
        "        logger.log_step(\"写入Notion数据库\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}（请检查数据库表头名称和类型是否与代码一致）\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        error_msg = f\"数据库写入失败: {str(e)}\"\n",
        "        logger.log_step(\"写入Notion数据库\", \"failed\", error=error_msg)\n",
        "        print(f\"❌ {error_msg}\")\n",
        "        return None\n",
        "\n",
        "# ======================\n",
        "# 输入处理\n",
        "# ======================\n",
        "def handle_input():\n",
        "    print(\"\\n=== 请选择输入方式 ===\")\n",
        "    print(\"1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\")\n",
        "    print(\"2: 上传带时间戳的转录文本 (.txt)\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"请选择 (1/2): \").strip() or \"1\"\n",
        "    except:\n",
        "        choice = \"1\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(\"\\n请上传音频文件（支持2-3小时会议录音）:\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"⚠️ 未检测到上传文件，请重试\")\n",
        "            return handle_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        audio_ext = os.path.splitext(filename)[1].lower()\n",
        "        supported_ext = ['.mp3', '.wav', '.m4a', '.opus']\n",
        "\n",
        "        if audio_ext not in supported_ext:\n",
        "            print(f\"❌ 不支持的文件格式（支持: {', '.join(supported_ext)}）\")\n",
        "            return handle_input()\n",
        "\n",
        "        audio_path = f\"/tmp/{filename}\"\n",
        "        with open(audio_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "\n",
        "        duration = get_audio_duration(audio_path)\n",
        "        if duration < 3600:\n",
        "            print(f\"⚠️ 检测到音频时长较短（{duration/60:.1f}分钟）\")\n",
        "            if input(\"是否继续使用长会议模式处理? (y/n): \").strip().lower() != 'y':\n",
        "                os.unlink(audio_path)\n",
        "                print(\"已切换到普通模式\")\n",
        "                return handle_input()\n",
        "\n",
        "        print(f\"🎵 音频信息: {filename}（{duration/60:.1f}分钟）\")\n",
        "\n",
        "        print(\"\\n⚡ 请选择转录模型:\")\n",
        "        print(\"1: base.en - 快速模式（适合清晰语音）\")\n",
        "        print(\"2: small.en - 平衡模式（推荐，速度与精度兼顾）\")\n",
        "        print(\"3: medium.en - 高精度模式（适合复杂会议）\")\n",
        "\n",
        "        model_choice = input(\"请选择 (1-3，默认2): \").strip() or \"2\"\n",
        "        model_map = {\"1\": \"base.en\", \"2\": \"small.en\", \"3\": \"medium.en\"}\n",
        "        model_size = model_map.get(model_choice, \"small.en\")\n",
        "        print(f\"将使用 {model_size} 模型进行转录\")\n",
        "\n",
        "        # 新增返回总时长（秒）\n",
        "        transcript, segments, primary_language, all_languages, total_seconds = transcribe_long_audio(audio_path, model_size)\n",
        "        return transcript, segments, primary_language, all_languages, total_seconds\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        print(\"\\n请上传带时间戳的转录文本（格式示例: [00:05:10] 发言人: ...）:\")\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"⚠️ 未检测到上传文件，请重试\")\n",
        "            return handle_input()\n",
        "\n",
        "        filename = next(iter(uploaded.keys()))\n",
        "        if not filename.endswith('.txt'):\n",
        "            print(\"❌ 仅支持.txt格式的文本文件\")\n",
        "            return handle_input()\n",
        "\n",
        "        try:\n",
        "            transcript_text = uploaded[filename].decode('utf-8')\n",
        "            segments = []\n",
        "            time_pattern = re.compile(r'\\[(\\d+:\\d+:\\d+)\\]')\n",
        "\n",
        "            for line in transcript_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                match = time_pattern.search(line)\n",
        "                if match:\n",
        "                    time_str = match.group(1)\n",
        "                    text = time_pattern.sub('', line).strip()\n",
        "                    h, m, s = map(int, time_str.split(':'))\n",
        "                    start_time = h * 3600 + m * 60 + s\n",
        "                    segments.append({\n",
        "                        \"text\": text,\n",
        "                        \"start\": start_time,\n",
        "                        \"end\": start_time + 30,\n",
        "                        \"language\": detect(text) if text.strip() else \"en\"\n",
        "                    })\n",
        "\n",
        "            if not segments:\n",
        "                raise ValueError(\"未检测到有效时间戳，请检查文本格式\")\n",
        "\n",
        "            # 计算总时长（秒）\n",
        "            total_seconds = segments[-1][\"end\"] - segments[0][\"start\"] if segments else 0\n",
        "\n",
        "            all_languages = list({seg[\"language\"] for seg in segments})\n",
        "            primary_language = all_languages[0] if all_languages else \"en\"\n",
        "            print(f\"✅ 已解析转录文本（{len(segments)}个片段，检测语言: {all_languages}）\")\n",
        "            return transcript_text, segments, primary_language, all_languages, total_seconds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 文本解析失败: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ 无效选择，默认使用音频输入\")\n",
        "        return handle_input()\n",
        "\n",
        "# ======================\n",
        "# 主函数\n",
        "# ======================\n",
        "def main():\n",
        "    print(\"=== 会议分析工具 ===\")\n",
        "    logger.log_step(\"会议处理流程\", \"started\")\n",
        "\n",
        "    try:\n",
        "        if not torch.cuda.is_available():\n",
        "            raise RuntimeError(\"请切换到GPU环境，请切换到GPU环境（Runtime > Change runtime type > 选择GPU）\")\n",
        "        print(f\"✅ 检测到GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "        # 处理输入（获取总时长）\n",
        "        transcript, segments, language, all_languages, total_seconds = handle_input()\n",
        "        if not transcript or not segments:\n",
        "            raise RuntimeError(\"未获取到有效会议内容\")\n",
        "\n",
        "        # 分析会议\n",
        "        meeting_data = analyze_meeting(segments, language)\n",
        "        if \"error\" in meeting_data:\n",
        "            raise RuntimeError(meeting_data[\"error\"])\n",
        "\n",
        "        # 补充语言信息到会议数据\n",
        "        meeting_data[\"all_languages\"] = all_languages\n",
        "\n",
        "        # 生成Notion报告\n",
        "        report_url = create_notion_report(meeting_data, segments)\n",
        "        if not report_url:\n",
        "            raise RuntimeError(\"无法生成Notion报告\")\n",
        "\n",
        "        # 写入数据库\n",
        "        db_entry_id = write_to_notion_database(meeting_data, transcript, all_languages, total_seconds)\n",
        "        if not db_entry_id:\n",
        "            raise RuntimeError(\"数据库写入失败，但报告已生成\")\n",
        "\n",
        "        # 保存日志并输出结果\n",
        "        log_file = logger.save_logs()\n",
        "        print(f\"\\n🎉 会议处理完成！\")\n",
        "        print(f\"📄 会议报告: {report_url}\")\n",
        "        print(f\"📊 数据库条目ID: {db_entry_id}\")\n",
        "        print(f\"📋 处理日志已保存到: {log_file}\")\n",
        "\n",
        "        from IPython.display import HTML\n",
        "        display(HTML(f'<a href=\"{report_url}\" target=\"_blank\">点击查看Notion会议报告</a>'))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.save_logs(\"meeting_error_logs.json\")\n",
        "        print(f\"\\n❌ 处理失败: {str(e)}\")\n",
        "        print(\"错误详情已保存到 meeting_error_logs.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "DnI0aBLIl8Mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c8e58e-03de-4a57-d2a4-39c1f48d01a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: faster-whisper==0.10.0 in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: av==11.* in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (11.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (0.15.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==0.10.0) (1.22.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.10.0) (1.1.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==0.10.0) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.10.0) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==0.10.0) (1.3.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-fmwzrpf_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-fmwzrpf_\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (1.26.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20250625) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: notion-client in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: langchain==0.1.13 in /usr/local/lib/python3.11/dist-packages (0.1.13)\n",
            "Requirement already satisfied: langchain-openai==0.0.8 in /usr/local/lib/python3.11/dist-packages (0.0.8)\n",
            "Requirement already satisfied: pydantic==2.5.2 in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: httpx==0.27.0 in /usr/local/lib/python3.11/dist-packages (0.27.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.13) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.0.8) (1.96.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.0.8) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.5.2) (4.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.0) (0.16.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.13) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.13) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain==0.1.13) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.13) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.13) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.13) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.13) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.13) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2024.11.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.13) (1.1.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "✅ 所有凭证已配置完成，准备处理会议内容\n",
            "=== 会议分析工具 ===\n",
            "✅ 检测到GPU: Tesla T4\n",
            "\n",
            "=== 请选择输入方式 ===\n",
            "1: 上传音频文件 (.mp3/.wav/.m4a/.opus)\n",
            "2: 上传带时间戳的转录文本 (.txt)\n",
            "请选择 (1/2): 1\n",
            "\n",
            "请上传音频文件（支持2-3小时会议录音）:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-427b77c4-4949-4686-9e21-75862bbd84c6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-427b77c4-4949-4686-9e21-75862bbd84c6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving DUO.mp3 to DUO.mp3\n",
            "⚠️ 检测到音频时长较短（29.7分钟）\n",
            "是否继续使用长会议模式处理? (y/n): y\n",
            "🎵 音频信息: DUO.mp3（29.7分钟）\n",
            "\n",
            "⚡ 请选择转录模型:\n",
            "1: base.en - 快速模式（适合清晰语音）\n",
            "2: small.en - 平衡模式（推荐，速度与精度兼顾）\n",
            "3: medium.en - 高精度模式（适合复杂会议）\n",
            "请选择 (1-3，默认2): 2\n",
            "将使用 small.en 模型进行转录\n",
            "📊 音频将分割为 3 块（每块15分钟，重叠30秒）\n",
            "🚀 开始转录 3 个分块...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r转录进度:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 加载 small.en 模型（首次运行需下载约1.5GB）...\n",
            "✅ 模型加载成功\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "转录进度: 100%|██████████| 3/3 [00:49<00:00, 16.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 转录完成（329个片段，主要语言: en，所有语言: ['en']）\n",
            "\n",
            "开始分析会议内容...\n",
            "📝 将会议内容分为 1 个分析块\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "分析进度: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 会议分析完成（3个话题，0个行动项）\n",
            "✅ 成功访问父页面: Parent Page\n",
            "✅ Notion报告已生成（总块数: 80）\n",
            "✅ 成功写入Notion数据库（条目ID: 2355fee1-8e37-819b-87c1-faffb148c942）\n",
            "⏱️ 会议时长: 0.0小时30.0分钟\n",
            "\n",
            "🎉 会议处理完成！\n",
            "📄 会议报告: https://www.notion.so/Simone-Ereau-s-Journey-to-Becoming-a-Radio-Host-2355fee18e3781039b26d2638f8cb764\n",
            "📊 数据库条目ID: 2355fee1-8e37-819b-87c1-faffb148c942\n",
            "📋 处理日志已保存到: meeting_logs.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"https://www.notion.so/Simone-Ereau-s-Journey-to-Becoming-a-Radio-Host-2355fee18e3781039b26d2638f8cb764\" target=\"_blank\">点击查看Notion会议报告</a>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLBE8pAfqJWAVmi7incS8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5225dd308a5d4cb48bc302acb181a51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d21b6d3ac7c4581aa961c2f137f69e5",
              "IPY_MODEL_05510ae00af1484688597ea503caabbb",
              "IPY_MODEL_80051aec09bc46bebf1d5ded88dd4c0b"
            ],
            "layout": "IPY_MODEL_09c17810f3804b26b6081a02656a1b18"
          }
        },
        "6d21b6d3ac7c4581aa961c2f137f69e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843c05f5495247b381100505b7c705c6",
            "placeholder": "​",
            "style": "IPY_MODEL_802582a9652746388242a5268447c6c0",
            "value": "config.json: "
          }
        },
        "05510ae00af1484688597ea503caabbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc8b29074ed48e1911f4e00a2a4d504",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_108d76ae6f0849329b4d676c664bc9ce",
            "value": 1
          }
        },
        "80051aec09bc46bebf1d5ded88dd4c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb1035b5d844018a8a3a4667667297e",
            "placeholder": "​",
            "style": "IPY_MODEL_70c9bc2c823c41ed9a20587c08392164",
            "value": " 2.66k/? [00:00&lt;00:00, 74.9kB/s]"
          }
        },
        "09c17810f3804b26b6081a02656a1b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843c05f5495247b381100505b7c705c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "802582a9652746388242a5268447c6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc8b29074ed48e1911f4e00a2a4d504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "108d76ae6f0849329b4d676c664bc9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbb1035b5d844018a8a3a4667667297e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c9bc2c823c41ed9a20587c08392164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d367cbf85394d18b92bb1eb2a084df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44b846a51b424fd596ffb878c653c4cf",
              "IPY_MODEL_8751f7b6210f415abe0dc830d008cf7d",
              "IPY_MODEL_47f335afd5fe494387deffc67087a5e4"
            ],
            "layout": "IPY_MODEL_a61edf70480d441d8d2e942672c864eb"
          }
        },
        "44b846a51b424fd596ffb878c653c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9242974f1a45442c808fa0705f352966",
            "placeholder": "​",
            "style": "IPY_MODEL_c27f195f3b3b464faade50443e552535",
            "value": "tokenizer.json: "
          }
        },
        "8751f7b6210f415abe0dc830d008cf7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534d82a48a1e461ab585882259d05c68",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2259349b9ea349788c3970bbe2c8ec83",
            "value": 1
          }
        },
        "47f335afd5fe494387deffc67087a5e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312bb335266d4ed69f8f7252305cd0fe",
            "placeholder": "​",
            "style": "IPY_MODEL_56c3c6fc295849079148c1a12c6e8044",
            "value": " 2.13M/? [00:00&lt;00:00, 20.9MB/s]"
          }
        },
        "a61edf70480d441d8d2e942672c864eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9242974f1a45442c808fa0705f352966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27f195f3b3b464faade50443e552535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "534d82a48a1e461ab585882259d05c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2259349b9ea349788c3970bbe2c8ec83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "312bb335266d4ed69f8f7252305cd0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c3c6fc295849079148c1a12c6e8044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "798068dc88924125ab22f10886f23128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_500cab9c8d54477b8d36e2db22a54977",
              "IPY_MODEL_91b0bed8d5fe4bed99769996f50e3cd1",
              "IPY_MODEL_e8fb5ed8a63d4ed19b984a4d2ad5b89b"
            ],
            "layout": "IPY_MODEL_a22957686d6e477fbe661dc8ec093028"
          }
        },
        "500cab9c8d54477b8d36e2db22a54977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d42717cecb9449796c0506f7424ffc3",
            "placeholder": "​",
            "style": "IPY_MODEL_c049b95701a84e1a9ba5a8724e055c98",
            "value": "vocabulary.txt: "
          }
        },
        "91b0bed8d5fe4bed99769996f50e3cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1efb88bd6b7b42d88a065122dd707a20",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95bfe467e7464e8aae9fd99facc8e8a6",
            "value": 1
          }
        },
        "e8fb5ed8a63d4ed19b984a4d2ad5b89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9d245e038440079e80a6d5ddef382b",
            "placeholder": "​",
            "style": "IPY_MODEL_dd2e117d0235474abf0627de4a9f6d02",
            "value": " 422k/? [00:00&lt;00:00, 5.70MB/s]"
          }
        },
        "a22957686d6e477fbe661dc8ec093028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d42717cecb9449796c0506f7424ffc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c049b95701a84e1a9ba5a8724e055c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efb88bd6b7b42d88a065122dd707a20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "95bfe467e7464e8aae9fd99facc8e8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c9d245e038440079e80a6d5ddef382b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2e117d0235474abf0627de4a9f6d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b76a8e7784a4af982866b0f86002d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aa693eef9df43309264df780dca2ac2",
              "IPY_MODEL_959b21bc5db542ff9d898f88ee0c6693",
              "IPY_MODEL_3b1bfa6c69604fbf84f326cb08464bed"
            ],
            "layout": "IPY_MODEL_40fa370d582544f4b9127b03f9c488cd"
          }
        },
        "1aa693eef9df43309264df780dca2ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd96c6f61a54489b1e4457c3c6a6014",
            "placeholder": "​",
            "style": "IPY_MODEL_5943bdf0509c472e8e5bb06f907eefb0",
            "value": "model.bin: 100%"
          }
        },
        "959b21bc5db542ff9d898f88ee0c6693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da30c836bdc460cab8d43cf1cd79f28",
            "max": 483545366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90d3160710484c0dab01c261f5618cf9",
            "value": 483545366
          }
        },
        "3b1bfa6c69604fbf84f326cb08464bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1bcff65e354aa9be14f2e0427da6e3",
            "placeholder": "​",
            "style": "IPY_MODEL_6337cdf81d1e4ed68b4991add998577e",
            "value": " 484M/484M [00:01&lt;00:00, 360MB/s]"
          }
        },
        "40fa370d582544f4b9127b03f9c488cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd96c6f61a54489b1e4457c3c6a6014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5943bdf0509c472e8e5bb06f907eefb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da30c836bdc460cab8d43cf1cd79f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d3160710484c0dab01c261f5618cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c1bcff65e354aa9be14f2e0427da6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6337cdf81d1e4ed68b4991add998577e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}