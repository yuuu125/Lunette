# -*- coding: utf-8 -*-
"""AI Meeting Assistant Core Pipeline (Stable Version).ipynb"""

# ===== 1. å®‰è£…ä¾èµ– =====
# ä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„ç‰ˆæœ¬ç»„åˆ
!pip install openai == 0.28.1 python - docx notion - client langdetect

# ===== 2. å¯¼å…¥åº“ =====
import os
import re
import json
import openai  # ä½¿ç”¨0.28ç‰ˆæœ¬çš„API
from docx import Document
from google.colab import files, userdata
from notion_client import Client
from langdetect import detect, LangDetectException
import datetime

# ===== 3. é…ç½®å¸¸é‡ =====
# å®‰å…¨åœ°ä»Colabå¯†é’¥ç®¡ç†è·å–APIå¯†é’¥
try:
    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
    NOTION_TOKEN = userdata.get('NOTION_TOKEN')
    NOTION_DB_ID = userdata.get('NOTION_DB_ID')

    # éªŒè¯å¯†é’¥æ˜¯å¦è·å–æˆåŠŸ
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEYæœªè®¾ç½®ï¼Œè¯·é€šè¿‡å·¦ä¾§é’¥åŒ™å›¾æ ‡æ·»åŠ å¯†é’¥")
    if not NOTION_TOKEN:
        print("âš ï¸ Notionä»¤ç‰Œæœªè®¾ç½®ï¼ŒNotionåŠŸèƒ½å°†ç¦ç”¨")
    if not NOTION_DB_ID:
        print("âš ï¸ Notionæ•°æ®åº“IDæœªè®¾ç½®ï¼ŒNotionåŠŸèƒ½å°†ç¦ç”¨")

    # è®¾ç½®OpenAI APIå¯†é’¥
    openai.api_key = OPENAI_API_KEY
    print("âœ… OpenAI APIå¯†é’¥å·²è®¾ç½®")

except Exception as e:
    print(f"âŒ å¯†é’¥è·å–å¤±è´¥: {str(e)}")
    # ä½œä¸ºå¤‡é€‰ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨è¿™é‡Œè®¾ç½®å¯†é’¥ï¼ˆä¸æ¨èï¼‰
    # OPENAI_API_KEY = "sk-..."
    # NOTION_TOKEN = "secret_..."
    # NOTION_DB_ID = "123456..."
    # openai.api_key = OPENAI_API_KEY


# ===== 4. æ–‡æœ¬è¾“å…¥æ¨¡å— =====
def handle_transcript_input():
    """å¤„ç†æ–‡æœ¬è¾“å…¥ï¼šä¸Šä¼ æ–‡ä»¶æˆ–ç²˜è´´æ–‡æœ¬"""
    print("\n=== å¤„ç†ä¼šè®®è®°å½•è¾“å…¥ ===")

    input_method = input("é€‰æ‹©è¾“å…¥æ–¹å¼ (1-ä¸Šä¼ æ–‡ä»¶, 2-ç²˜è´´æ–‡æœ¬): ")
    transcript_text = ""

    # é€‰é¡¹1ï¼šæ–‡ä»¶ä¸Šä¼ 
    if input_method == "1":
        uploaded = files.upload()
        if not uploaded:
            print("âš ï¸ æœªä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨ç²˜è´´æ–‡æœ¬æ–¹å¼")
            transcript_text = input("ç²˜è´´ä¼šè®®è®°å½•æ–‡æœ¬: ")
        else:
            filename = list(uploaded.keys())[0]
            print(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")

            # å¤„ç†æ–‡æœ¬æ–‡ä»¶
            if filename.endswith('.txt'):
                transcript_text = uploaded[filename].decode('utf-8')

            # å¤„ç†Wordæ–‡æ¡£
            elif filename.endswith('.docx'):
                doc = Document(filename)
                transcript_text = "\n".join([para.text for para in doc.paragraphs])

            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨.txtæˆ–.docx")

    # é€‰é¡¹2ï¼šç²˜è´´æ–‡æœ¬
    elif input_method == "2":
        transcript_text = input("ç²˜è´´ä¼šè®®è®°å½•æ–‡æœ¬: ")

    # æ¸…ç†æ–‡æœ¬
    cleaned_text = clean_transcript(transcript_text)
    segments = segment_text(cleaned_text)

    print(f"ğŸ“ æ–‡æœ¬å¤„ç†å®Œæˆ: {len(segments)}ä¸ªæ®µè½")
    return cleaned_text, segments


# æ·»åŠ æµ‹è¯•è¿æ¥å‡½æ•°
def test_notion_connection():
    try:
        notion = Client(auth=NOTION_TOKEN)
        db_info = notion.databases.retrieve(database_id=NOTION_DB_ID)
        print("âœ… Notionè¿æ¥æˆåŠŸ!")
        print(f"æ•°æ®åº“åç§°: {db_info['title'][0]['text']['content']}")
        print("æ•°æ®åº“å±æ€§:", list(db_info['properties'].keys()))
        return True
    except Exception as e:
        print(f"âŒ Notionè¿æ¥å¤±è´¥: {str(e)}")
        return False


def clean_transcript(text):
    """æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤æ—¶é—´æˆ³å’Œè¯´è¯äººæ ‡è¯†"""
    # ç§»é™¤æ—¶é—´æˆ³ (00:00:00æ ¼å¼)
    text = re.sub(r'\d{1,2}:\d{2}:\d{2}', '', text)
    # ç§»é™¤è¯´è¯äººæ ‡è¯† (Speaker 1:)
    text = re.sub(r'Speaker\s*\d+:?', '', text)
    # ç§»é™¤å¤šä½™ç©ºè¡Œ
    return re.sub(r'\n\s*\n', '\n\n', text).strip()


def segment_text(text):
    """ç®€å•åˆ†æ®µé€»è¾‘"""
    return [p.strip() for p in text.split('\n\n') if p.strip()]


# ===== 5. GPTæ‘˜è¦å’Œå…³é”®ç‚¹æå– (ä½¿ç”¨0.28ç‰ˆæœ¬API) =====
def analyze_with_gpt(text, language='en'):
    """ä½¿ç”¨GPTåˆ†æä¼šè®®è®°å½•"""
    print("\n=== ä½¿ç”¨GPTåˆ†æä¼šè®®è®°å½• ===")

    if not openai.api_key:
        print("âŒ OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return {"error": "OpenAI APIå¯†é’¥æœªè®¾ç½®", "fallback_used": True}, 0

    # å¤šè¯­è¨€æ”¯æŒ
    lang_map = {'zh': 'Chinese', 'es': 'Spanish', 'fr': 'French', 'en': 'English'}
    lang_name = lang_map.get(language[:2], 'English')

    # ç³»ç»Ÿæç¤ºè¯ - å¢å¼ºç‰ˆï¼Œæ·»åŠ ä¼šè®®æ ‡é¢˜å’Œå‚ä¼šäººæå–
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®åˆ†æå¸ˆï¼Œè¯·ä»ä»¥ä¸‹ä¼šè®®è®°å½•ä¸­æå–å…³é”®ä¿¡æ¯ï¼š
    - ä½¿ç”¨{lang_name}å›å¤
    - å¦‚æœæ— æ³•è¯†åˆ«è¯­è¨€ï¼Œä½¿ç”¨è‹±è¯­
    - æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
    {{
        "meeting_title": "ä¼šè®®æ ‡é¢˜",
        "participants": ["å‚ä¼šäºº1", "å‚ä¼šäºº2", ...],
        "summary": "ä¼šè®®æ‘˜è¦",
        "action_items": [{{"task": "ä»»åŠ¡æè¿°", "assignee": "è´Ÿè´£äºº"}}],
        "key_points": {{
            "concerns": [],
            "decisions": [],
            "deadlines": [],
            "updates": []
        }},
        "meeting_type": "ä¼šè®®ç±»å‹",
        "platform": "ä¼šè®®å¹³å°",
        "fallback_used": false
    }}

    æå–è§„åˆ™ï¼š
    1. meeting_title: ä»ä¼šè®®è®°å½•å¼€å¤´æˆ–ç»“å°¾æå–ä¼šè®®æ ‡é¢˜ï¼Œå¦‚æœªæ˜ç¡®æåŠåˆ™æ ¹æ®å†…å®¹ç”Ÿæˆç®€æ´æ ‡é¢˜
    2. participants: æå–æ‰€æœ‰å‚ä¼šäººå§“åï¼Œä¼˜å…ˆæå–æ˜ç¡®æåˆ°çš„å‚ä¼šäººåˆ—è¡¨
    3. é‡ç‚¹å…³æ³¨ä¼šè®®å¼€å¤´å’Œç»“å°¾éƒ¨åˆ†ï¼Œè¿™äº›åœ°æ–¹é€šå¸¸åŒ…å«ä¼šè®®æ ‡é¢˜å’Œå‚ä¼šäººä¿¡æ¯
    """

    # ç”¨æˆ·æç¤ºè¯
    user_prompt = f"ä¼šè®®è®°å½•ï¼š\n{text[:10000]}"  # é™åˆ¶é•¿åº¦

    try:
        # ä½¿ç”¨0.28ç‰ˆæœ¬çš„APIè°ƒç”¨
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )

        # è§£æå“åº”
        content = response.choices[0].message['content']
        result = json.loads(content)
        tokens_used = response.usage['total_tokens']

        print(f"âœ… GPTåˆ†æå®Œæˆ! ä½¿ç”¨token: {tokens_used}")
        print(f"ä¼šè®®æ ‡é¢˜: {result.get('meeting_title', 'æœªçŸ¥')}")
        print(f"å‚ä¼šäººæ•°: {len(result.get('participants', []))}")
        print(f"ä¼šè®®ç±»å‹: {result.get('meeting_type', 'æœªçŸ¥')}")
        print(f"è¡ŒåŠ¨é¡¹æ•°é‡: {len(result.get('action_items', []))}")

        # è¡ŒåŠ¨é¡¹å›é€€æœºåˆ¶
        if not result.get('action_items'):
            result['fallback_used'] = True
            print("âš ï¸ æœªæ£€æµ‹åˆ°è¡ŒåŠ¨é¡¹ï¼Œå¯ç”¨å›é€€æœºåˆ¶")

        return result, tokens_used

    except Exception as e:
        print(f"âŒ GPTåˆ†æå¤±è´¥: {str(e)}")
        return {
            "error": str(e),
            "fallback_used": True
        }, 0


# ===== 6. Notionæ•°æ®åº“é›†æˆ =====
def create_notion_entry(meeting_data):
    """åœ¨Notionæ•°æ®åº“ä¸­åˆ›å»ºæ¡ç›®"""
    if not NOTION_TOKEN or not NOTION_DB_ID:
        print("âš ï¸ Notioné…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡åŒæ­¥")
        return False

    print("\n=== åŒæ­¥åˆ°Notionæ•°æ®åº“ ===")

    try:
        notion = Client(auth=NOTION_TOKEN)

        # å‡†å¤‡å±æ€§ - ä½¿ç”¨è‡ªåŠ¨æå–çš„ä¼šè®®æ ‡é¢˜å’Œå‚ä¼šäºº
        properties = {
            "Meeting Title": {"title": [{"text": {"content": meeting_data.get("meeting_title", "æœªå‘½åä¼šè®®")}}]},
            "Participant": {
                "rich_text": [{"text": {"content": ", ".join(meeting_data.get("participants", ["æœªçŸ¥"]))}}]},
            "Date & Duration": {"date": {"start": meeting_data.get("date", datetime.datetime.now().isoformat())}},
            "Meeting Type": {"select": {"name": meeting_data.get("meeting_type", "å…¶ä»–")}},
            "Platform": {"select": {"name": meeting_data.get("platform", "æœªçŸ¥å¹³å°")}},
            "Summary": {"rich_text": [{"text": {"content": meeting_data.get("summary", "")}}]},
            "Key Points": {"rich_text": [{"text": {"content": format_key_points(meeting_data)}}]},
            "Action Items": {"rich_text": [{"text": {"content": format_action_items(meeting_data)}}]},
        }

        # åˆ›å»ºæ–°æ¡ç›®
        new_page = notion.pages.create(
            parent={"database_id": NOTION_DB_ID},
            properties=properties
        )

        print(f"âœ… Notionæ¡ç›®åˆ›å»ºæˆåŠŸ! ID: {new_page['id']}")
        return True
    except Exception as e:
        print(f"âŒ NotionåŒæ­¥å¤±è´¥: {str(e)}")
        return False


def format_key_points(data):
    """æ ¼å¼åŒ–å…³é”®ç‚¹"""
    points = []
    key_points = data.get("key_points", {})
    for category, items in key_points.items():
        if items and isinstance(items, list):
            points.append(f"{category.upper()}:")
            points.extend([f"- {item}" for item in items])
    return "\n".join(points)


def format_action_items(data):
    """æ ¼å¼åŒ–è¡ŒåŠ¨é¡¹"""
    action_items = data.get("action_items", [])
    if not action_items or not isinstance(action_items, list):
        return "æ— æ˜ç¡®è¡ŒåŠ¨é¡¹"

    formatted = []
    for item in action_items:
        if isinstance(item, dict):
            task = item.get('task', 'æœªçŸ¥ä»»åŠ¡')
            assignee = item.get('assignee', 'å¾…åˆ†é…')
            formatted.append(f"- {task} (è´Ÿè´£äºº: {assignee})")
        else:
            formatted.append(f"- {str(item)}")
    return "\n".join(formatted)


# ===== 7. Whisperé›†æˆï¼ˆå‡†å¤‡é˜¶æ®µï¼‰ =====
def setup_whisper():
    """å®‰è£…Whisperå¹¶æµ‹è¯•"""
    print("\n=== å‡†å¤‡Whisperè¯­éŸ³è¯†åˆ« ===")
    !pip
    install
    git + https: // github.com / openai / whisper.git
    !sudo
    apt
    update & & sudo
    apt
    install
    ffmpeg

    # æµ‹è¯•éŸ³é¢‘ä¸Šä¼ 
    uploaded_audio = files.upload()
    if uploaded_audio:
        audio_file = list(uploaded_audio.keys())[0]
        print(f"ğŸ”Š éŸ³é¢‘æ ·æœ¬å·²ä¸Šä¼ : {audio_file}")
        return audio_file
    return None


# ===== 8. ä¸»å·¥ä½œæµç¨‹ =====
def main():
    """æ ¸å¿ƒå·¥ä½œæµç¨‹"""
    if not openai.api_key:
        print("âŒ OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œæ— æ³•è¿è¡Œå·¥ä½œæµç¨‹")
        return

    logs = {"steps": [], "errors": []}

    # åœ¨å¼€å§‹å¤„æ·»åŠ è¿æ¥æµ‹è¯•
    if NOTION_TOKEN and NOTION_DB_ID:
        if not test_notion_connection():
            print("âš ï¸ Notionè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

    try:
        # æ­¥éª¤1: è¾“å…¥å¤„ç†
        cleaned_text, segments = handle_transcript_input()
        logs["steps"].append({
            "step": "æ–‡æœ¬è¾“å…¥",
            "segment_count": len(segments),
            "status": "success"
        })

        # æ­¥éª¤2: GPTåˆ†æ
        try:
            # å°è¯•æ£€æµ‹è¯­è¨€
            language = detect(cleaned_text[:500]) if cleaned_text else 'en'
        except LangDetectException:
            language = 'en'

        gpt_results, tokens_used = analyze_with_gpt(cleaned_text, language)

        # å¤„ç†å¯èƒ½çš„GPTé”™è¯¯
        if "error" in gpt_results:
            logs["steps"].append({
                "step": "GPTåˆ†æ",
                "status": "failed",
                "error": gpt_results["error"]
            })
            print(f"âŒ GPTåˆ†æå¤±è´¥: {gpt_results['error']}")
            return
        else:
            logs["steps"].append({
                "step": "GPTåˆ†æ",
                "tokens_used": tokens_used,
                "meeting_title": gpt_results.get("meeting_title"),
                "participants_count": len(gpt_results.get("participants", [])),
                "meeting_type": gpt_results.get("meeting_type"),
                "action_items_count": len(gpt_results.get("action_items", [])),
                "status": "success"
            })

        # æ­¥éª¤3: NotionåŒæ­¥
        # æ·»åŠ æ—¥æœŸä¿¡æ¯
        gpt_results["date"] = datetime.datetime.now().isoformat()

        # åˆ›å»ºNotionæ¡ç›®
        notion_success = create_notion_entry(gpt_results)
        logs["steps"].append({
            "step": "NotionåŒæ­¥",
            "status": "success" if notion_success else "failed"
        })

        # ä¿å­˜æ—¥å¿—
        with open("meeting_logs.json", "w") as f:
            json.dump(logs, f, indent=2)

        print("\nâœ… æµç¨‹å®Œæˆ! æ—¥å¿—å·²ä¿å­˜")

    except Exception as e:
        logs["errors"].append(str(e))
        print(f"\nâŒ æµç¨‹å‡ºé”™: {str(e)}")
        with open("error_log.json", "w") as f:
            json.dump(logs, f, indent=2)


# ===== 9. æ‰§è¡Œä¸»å‡½æ•° =====
if __name__ == "__main__":
    main()